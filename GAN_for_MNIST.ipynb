{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c7b8677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 17:52:41.825454: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-22 17:52:42.638912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a67722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,features):\n",
    "        super().__init__()\n",
    "        self.discr=nn.Sequential(\n",
    "            nn.Linear(features,128),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(128,1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.discr(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "630faee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,n_dim,img_dim):\n",
    "        super().__init__()\n",
    "        self.genr=nn.Sequential(\n",
    "            nn.Linear(n_dim,256),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(256,img_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.genr(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b76ae85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93677149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr=3e-4\n",
    "n_dim=128\n",
    "image_dim=28*28*1 #784 pixels\n",
    "batch_size=32\n",
    "epochs=1000\n",
    "\n",
    "discr=Discriminator(image_dim).to(device)\n",
    "genr=Generator(n_dim,image_dim).to(device)\n",
    "fixed_noise=torch.randn((batch_size,n_dim)).to(device)\n",
    "transforms=transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5,),(0.5,)),\n",
    "    ]\n",
    ")\n",
    "datasets=datasets.MNIST(root=\"dataset/\",transform=transforms,download=True)\n",
    "loader=DataLoader(dataset=datasets,batch_size=batch_size,shuffle=True)\n",
    "opt_discr=optim.Adam(discr.parameters(),lr=lr)\n",
    "opt_genr=optim.Adam(genr.parameters(),lr=lr)\n",
    "loss=nn.BCELoss()\n",
    "writer_fake=SummaryWriter(f\"runs/fake\")\n",
    "writer_real=SummaryWriter(f\"runs/real\")\n",
    "step=0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "671a02b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [0/1000] \\ Loss D: 0.6852  \\ Loss G: 0.7211 \\ \n",
      "Epoch : [1/1000] \\ Loss D: 0.5952  \\ Loss G: 0.8887 \\ \n",
      "Epoch : [2/1000] \\ Loss D: 1.0799  \\ Loss G: 0.5077 \\ \n",
      "Epoch : [3/1000] \\ Loss D: 0.3034  \\ Loss G: 1.6203 \\ \n",
      "Epoch : [4/1000] \\ Loss D: 0.4128  \\ Loss G: 1.1523 \\ \n",
      "Epoch : [5/1000] \\ Loss D: 0.5446  \\ Loss G: 1.2272 \\ \n",
      "Epoch : [6/1000] \\ Loss D: 0.5561  \\ Loss G: 1.0598 \\ \n",
      "Epoch : [7/1000] \\ Loss D: 0.4283  \\ Loss G: 1.8957 \\ \n",
      "Epoch : [8/1000] \\ Loss D: 0.6828  \\ Loss G: 1.1789 \\ \n",
      "Epoch : [9/1000] \\ Loss D: 0.5966  \\ Loss G: 1.4175 \\ \n",
      "Epoch : [10/1000] \\ Loss D: 0.4156  \\ Loss G: 1.4599 \\ \n",
      "Epoch : [11/1000] \\ Loss D: 0.7805  \\ Loss G: 1.1069 \\ \n",
      "Epoch : [12/1000] \\ Loss D: 0.5806  \\ Loss G: 1.5629 \\ \n",
      "Epoch : [13/1000] \\ Loss D: 0.9200  \\ Loss G: 1.1610 \\ \n",
      "Epoch : [14/1000] \\ Loss D: 0.7108  \\ Loss G: 0.8963 \\ \n",
      "Epoch : [15/1000] \\ Loss D: 0.4416  \\ Loss G: 1.4987 \\ \n",
      "Epoch : [16/1000] \\ Loss D: 0.5630  \\ Loss G: 1.5920 \\ \n",
      "Epoch : [17/1000] \\ Loss D: 0.7654  \\ Loss G: 1.2619 \\ \n",
      "Epoch : [18/1000] \\ Loss D: 0.5005  \\ Loss G: 1.1992 \\ \n",
      "Epoch : [19/1000] \\ Loss D: 0.5524  \\ Loss G: 1.9165 \\ \n",
      "Epoch : [20/1000] \\ Loss D: 0.3793  \\ Loss G: 1.8172 \\ \n",
      "Epoch : [21/1000] \\ Loss D: 0.5909  \\ Loss G: 1.3375 \\ \n",
      "Epoch : [22/1000] \\ Loss D: 0.5365  \\ Loss G: 1.7912 \\ \n",
      "Epoch : [23/1000] \\ Loss D: 0.5547  \\ Loss G: 1.4189 \\ \n",
      "Epoch : [24/1000] \\ Loss D: 0.6228  \\ Loss G: 1.2716 \\ \n",
      "Epoch : [25/1000] \\ Loss D: 0.6974  \\ Loss G: 1.5382 \\ \n",
      "Epoch : [26/1000] \\ Loss D: 0.6292  \\ Loss G: 1.6410 \\ \n",
      "Epoch : [27/1000] \\ Loss D: 0.5628  \\ Loss G: 2.0854 \\ \n",
      "Epoch : [28/1000] \\ Loss D: 0.4001  \\ Loss G: 1.9945 \\ \n",
      "Epoch : [29/1000] \\ Loss D: 0.6114  \\ Loss G: 1.5193 \\ \n",
      "Epoch : [30/1000] \\ Loss D: 0.9218  \\ Loss G: 1.2657 \\ \n",
      "Epoch : [31/1000] \\ Loss D: 0.6397  \\ Loss G: 1.2902 \\ \n",
      "Epoch : [32/1000] \\ Loss D: 0.6032  \\ Loss G: 1.0449 \\ \n",
      "Epoch : [33/1000] \\ Loss D: 0.6530  \\ Loss G: 1.1756 \\ \n",
      "Epoch : [34/1000] \\ Loss D: 0.5309  \\ Loss G: 1.4714 \\ \n",
      "Epoch : [35/1000] \\ Loss D: 0.4909  \\ Loss G: 1.6273 \\ \n",
      "Epoch : [36/1000] \\ Loss D: 0.4901  \\ Loss G: 1.5668 \\ \n",
      "Epoch : [37/1000] \\ Loss D: 0.8421  \\ Loss G: 0.9676 \\ \n",
      "Epoch : [38/1000] \\ Loss D: 0.5186  \\ Loss G: 1.6066 \\ \n",
      "Epoch : [39/1000] \\ Loss D: 0.7474  \\ Loss G: 1.2450 \\ \n",
      "Epoch : [40/1000] \\ Loss D: 0.7208  \\ Loss G: 1.3083 \\ \n",
      "Epoch : [41/1000] \\ Loss D: 0.5622  \\ Loss G: 1.4122 \\ \n",
      "Epoch : [42/1000] \\ Loss D: 0.6979  \\ Loss G: 1.0790 \\ \n",
      "Epoch : [43/1000] \\ Loss D: 0.7605  \\ Loss G: 0.9914 \\ \n",
      "Epoch : [44/1000] \\ Loss D: 0.5579  \\ Loss G: 1.5583 \\ \n",
      "Epoch : [45/1000] \\ Loss D: 0.5979  \\ Loss G: 1.6901 \\ \n",
      "Epoch : [46/1000] \\ Loss D: 0.6577  \\ Loss G: 0.9405 \\ \n",
      "Epoch : [47/1000] \\ Loss D: 0.5435  \\ Loss G: 1.1774 \\ \n",
      "Epoch : [48/1000] \\ Loss D: 0.5437  \\ Loss G: 1.2757 \\ \n",
      "Epoch : [49/1000] \\ Loss D: 0.4531  \\ Loss G: 1.3394 \\ \n",
      "Epoch : [50/1000] \\ Loss D: 0.6074  \\ Loss G: 1.3542 \\ \n",
      "Epoch : [51/1000] \\ Loss D: 0.6494  \\ Loss G: 1.0058 \\ \n",
      "Epoch : [52/1000] \\ Loss D: 0.6348  \\ Loss G: 1.1644 \\ \n",
      "Epoch : [53/1000] \\ Loss D: 0.5819  \\ Loss G: 1.1185 \\ \n",
      "Epoch : [54/1000] \\ Loss D: 0.5524  \\ Loss G: 1.3025 \\ \n",
      "Epoch : [55/1000] \\ Loss D: 0.7243  \\ Loss G: 0.9477 \\ \n",
      "Epoch : [56/1000] \\ Loss D: 0.6630  \\ Loss G: 0.8752 \\ \n",
      "Epoch : [57/1000] \\ Loss D: 0.6226  \\ Loss G: 0.9416 \\ \n",
      "Epoch : [58/1000] \\ Loss D: 0.6155  \\ Loss G: 0.9190 \\ \n",
      "Epoch : [59/1000] \\ Loss D: 0.5741  \\ Loss G: 1.1505 \\ \n",
      "Epoch : [60/1000] \\ Loss D: 0.5582  \\ Loss G: 1.1880 \\ \n",
      "Epoch : [61/1000] \\ Loss D: 0.6394  \\ Loss G: 0.8545 \\ \n",
      "Epoch : [62/1000] \\ Loss D: 0.6879  \\ Loss G: 0.9499 \\ \n",
      "Epoch : [63/1000] \\ Loss D: 0.6775  \\ Loss G: 0.7967 \\ \n",
      "Epoch : [64/1000] \\ Loss D: 0.7458  \\ Loss G: 0.9389 \\ \n",
      "Epoch : [65/1000] \\ Loss D: 0.5518  \\ Loss G: 1.1444 \\ \n",
      "Epoch : [66/1000] \\ Loss D: 0.5988  \\ Loss G: 0.8756 \\ \n",
      "Epoch : [67/1000] \\ Loss D: 0.6644  \\ Loss G: 0.8023 \\ \n",
      "Epoch : [68/1000] \\ Loss D: 0.6818  \\ Loss G: 1.0501 \\ \n",
      "Epoch : [69/1000] \\ Loss D: 0.7759  \\ Loss G: 0.7804 \\ \n",
      "Epoch : [70/1000] \\ Loss D: 0.7252  \\ Loss G: 0.9483 \\ \n",
      "Epoch : [71/1000] \\ Loss D: 0.5911  \\ Loss G: 0.8783 \\ \n",
      "Epoch : [72/1000] \\ Loss D: 0.6736  \\ Loss G: 0.7904 \\ \n",
      "Epoch : [73/1000] \\ Loss D: 0.6733  \\ Loss G: 0.8969 \\ \n",
      "Epoch : [74/1000] \\ Loss D: 0.6096  \\ Loss G: 0.8422 \\ \n",
      "Epoch : [75/1000] \\ Loss D: 0.5689  \\ Loss G: 0.8571 \\ \n",
      "Epoch : [76/1000] \\ Loss D: 0.5782  \\ Loss G: 0.8895 \\ \n",
      "Epoch : [77/1000] \\ Loss D: 0.6601  \\ Loss G: 0.9456 \\ \n",
      "Epoch : [78/1000] \\ Loss D: 0.6974  \\ Loss G: 0.7632 \\ \n",
      "Epoch : [79/1000] \\ Loss D: 0.5960  \\ Loss G: 0.9815 \\ \n",
      "Epoch : [80/1000] \\ Loss D: 0.6796  \\ Loss G: 0.8104 \\ \n",
      "Epoch : [81/1000] \\ Loss D: 0.6441  \\ Loss G: 0.8745 \\ \n",
      "Epoch : [82/1000] \\ Loss D: 0.5603  \\ Loss G: 1.0048 \\ \n",
      "Epoch : [83/1000] \\ Loss D: 0.5788  \\ Loss G: 0.9926 \\ \n",
      "Epoch : [84/1000] \\ Loss D: 0.6233  \\ Loss G: 0.9487 \\ \n",
      "Epoch : [85/1000] \\ Loss D: 0.6521  \\ Loss G: 0.9322 \\ \n",
      "Epoch : [86/1000] \\ Loss D: 0.7065  \\ Loss G: 0.6993 \\ \n",
      "Epoch : [87/1000] \\ Loss D: 0.5557  \\ Loss G: 1.0270 \\ \n",
      "Epoch : [88/1000] \\ Loss D: 0.6073  \\ Loss G: 1.0497 \\ \n",
      "Epoch : [89/1000] \\ Loss D: 0.5622  \\ Loss G: 0.8966 \\ \n",
      "Epoch : [90/1000] \\ Loss D: 0.6283  \\ Loss G: 0.8786 \\ \n",
      "Epoch : [91/1000] \\ Loss D: 0.5849  \\ Loss G: 1.0637 \\ \n",
      "Epoch : [92/1000] \\ Loss D: 0.5716  \\ Loss G: 0.9335 \\ \n",
      "Epoch : [93/1000] \\ Loss D: 0.6532  \\ Loss G: 0.9149 \\ \n",
      "Epoch : [94/1000] \\ Loss D: 0.6229  \\ Loss G: 0.8439 \\ \n",
      "Epoch : [95/1000] \\ Loss D: 0.6543  \\ Loss G: 1.1849 \\ \n",
      "Epoch : [96/1000] \\ Loss D: 0.6107  \\ Loss G: 0.9314 \\ \n",
      "Epoch : [97/1000] \\ Loss D: 0.6737  \\ Loss G: 0.8184 \\ \n",
      "Epoch : [98/1000] \\ Loss D: 0.5339  \\ Loss G: 1.0874 \\ \n",
      "Epoch : [99/1000] \\ Loss D: 0.5989  \\ Loss G: 1.1261 \\ \n",
      "Epoch : [100/1000] \\ Loss D: 0.6089  \\ Loss G: 1.1090 \\ \n",
      "Epoch : [101/1000] \\ Loss D: 0.5998  \\ Loss G: 1.0079 \\ \n",
      "Epoch : [102/1000] \\ Loss D: 0.5672  \\ Loss G: 0.9512 \\ \n",
      "Epoch : [103/1000] \\ Loss D: 0.5785  \\ Loss G: 1.0399 \\ \n",
      "Epoch : [104/1000] \\ Loss D: 0.6776  \\ Loss G: 0.8540 \\ \n",
      "Epoch : [105/1000] \\ Loss D: 0.6057  \\ Loss G: 1.1167 \\ \n",
      "Epoch : [106/1000] \\ Loss D: 0.6298  \\ Loss G: 0.9778 \\ \n",
      "Epoch : [107/1000] \\ Loss D: 0.6077  \\ Loss G: 0.9721 \\ \n",
      "Epoch : [108/1000] \\ Loss D: 0.5994  \\ Loss G: 0.9855 \\ \n",
      "Epoch : [109/1000] \\ Loss D: 0.6936  \\ Loss G: 0.9866 \\ \n",
      "Epoch : [110/1000] \\ Loss D: 0.6567  \\ Loss G: 0.8682 \\ \n",
      "Epoch : [111/1000] \\ Loss D: 0.6255  \\ Loss G: 0.8813 \\ \n",
      "Epoch : [112/1000] \\ Loss D: 0.6056  \\ Loss G: 1.0131 \\ \n",
      "Epoch : [113/1000] \\ Loss D: 0.6308  \\ Loss G: 0.8831 \\ \n",
      "Epoch : [114/1000] \\ Loss D: 0.5860  \\ Loss G: 0.9131 \\ \n",
      "Epoch : [115/1000] \\ Loss D: 0.6211  \\ Loss G: 1.1549 \\ \n",
      "Epoch : [116/1000] \\ Loss D: 0.6431  \\ Loss G: 1.0475 \\ \n",
      "Epoch : [117/1000] \\ Loss D: 0.6788  \\ Loss G: 0.8527 \\ \n",
      "Epoch : [118/1000] \\ Loss D: 0.5971  \\ Loss G: 1.0358 \\ \n",
      "Epoch : [119/1000] \\ Loss D: 0.6608  \\ Loss G: 0.7261 \\ \n",
      "Epoch : [120/1000] \\ Loss D: 0.4765  \\ Loss G: 1.2241 \\ \n",
      "Epoch : [121/1000] \\ Loss D: 0.6962  \\ Loss G: 0.8845 \\ \n",
      "Epoch : [122/1000] \\ Loss D: 0.5162  \\ Loss G: 1.0132 \\ \n",
      "Epoch : [123/1000] \\ Loss D: 0.5074  \\ Loss G: 1.0847 \\ \n",
      "Epoch : [124/1000] \\ Loss D: 0.6696  \\ Loss G: 0.8792 \\ \n",
      "Epoch : [125/1000] \\ Loss D: 0.6066  \\ Loss G: 0.9422 \\ \n",
      "Epoch : [126/1000] \\ Loss D: 0.5807  \\ Loss G: 0.9168 \\ \n",
      "Epoch : [127/1000] \\ Loss D: 0.6135  \\ Loss G: 1.0159 \\ \n",
      "Epoch : [128/1000] \\ Loss D: 0.6727  \\ Loss G: 0.9261 \\ \n",
      "Epoch : [129/1000] \\ Loss D: 0.6407  \\ Loss G: 0.9025 \\ \n",
      "Epoch : [130/1000] \\ Loss D: 0.6698  \\ Loss G: 0.9920 \\ \n",
      "Epoch : [131/1000] \\ Loss D: 0.5369  \\ Loss G: 1.0157 \\ \n",
      "Epoch : [132/1000] \\ Loss D: 0.6256  \\ Loss G: 1.0757 \\ \n",
      "Epoch : [133/1000] \\ Loss D: 0.5529  \\ Loss G: 0.9089 \\ \n",
      "Epoch : [134/1000] \\ Loss D: 0.6428  \\ Loss G: 1.0327 \\ \n",
      "Epoch : [135/1000] \\ Loss D: 0.5762  \\ Loss G: 0.8871 \\ \n",
      "Epoch : [136/1000] \\ Loss D: 0.6681  \\ Loss G: 0.8527 \\ \n",
      "Epoch : [137/1000] \\ Loss D: 0.5793  \\ Loss G: 1.1204 \\ \n",
      "Epoch : [138/1000] \\ Loss D: 0.6044  \\ Loss G: 1.1059 \\ \n",
      "Epoch : [139/1000] \\ Loss D: 0.6147  \\ Loss G: 1.0833 \\ \n",
      "Epoch : [140/1000] \\ Loss D: 0.5687  \\ Loss G: 1.0152 \\ \n",
      "Epoch : [141/1000] \\ Loss D: 0.6114  \\ Loss G: 1.0658 \\ \n",
      "Epoch : [142/1000] \\ Loss D: 0.5077  \\ Loss G: 1.1425 \\ \n",
      "Epoch : [143/1000] \\ Loss D: 0.5709  \\ Loss G: 1.0224 \\ \n",
      "Epoch : [144/1000] \\ Loss D: 0.6305  \\ Loss G: 1.0652 \\ \n",
      "Epoch : [145/1000] \\ Loss D: 0.5520  \\ Loss G: 1.0634 \\ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [146/1000] \\ Loss D: 0.5153  \\ Loss G: 1.2893 \\ \n",
      "Epoch : [147/1000] \\ Loss D: 0.6329  \\ Loss G: 1.0249 \\ \n",
      "Epoch : [148/1000] \\ Loss D: 0.6427  \\ Loss G: 0.9332 \\ \n",
      "Epoch : [149/1000] \\ Loss D: 0.5804  \\ Loss G: 1.0995 \\ \n",
      "Epoch : [150/1000] \\ Loss D: 0.6237  \\ Loss G: 1.0302 \\ \n",
      "Epoch : [151/1000] \\ Loss D: 0.5177  \\ Loss G: 1.1186 \\ \n",
      "Epoch : [152/1000] \\ Loss D: 0.6808  \\ Loss G: 1.0409 \\ \n",
      "Epoch : [153/1000] \\ Loss D: 0.5604  \\ Loss G: 1.1594 \\ \n",
      "Epoch : [154/1000] \\ Loss D: 0.5316  \\ Loss G: 0.9134 \\ \n",
      "Epoch : [155/1000] \\ Loss D: 0.7113  \\ Loss G: 1.0271 \\ \n",
      "Epoch : [156/1000] \\ Loss D: 0.6547  \\ Loss G: 0.9884 \\ \n",
      "Epoch : [157/1000] \\ Loss D: 0.6738  \\ Loss G: 0.8354 \\ \n",
      "Epoch : [158/1000] \\ Loss D: 0.6034  \\ Loss G: 1.0715 \\ \n",
      "Epoch : [159/1000] \\ Loss D: 0.5861  \\ Loss G: 1.0469 \\ \n",
      "Epoch : [160/1000] \\ Loss D: 0.5099  \\ Loss G: 1.1090 \\ \n",
      "Epoch : [161/1000] \\ Loss D: 0.6271  \\ Loss G: 0.8222 \\ \n",
      "Epoch : [162/1000] \\ Loss D: 0.5492  \\ Loss G: 0.9158 \\ \n",
      "Epoch : [163/1000] \\ Loss D: 0.5690  \\ Loss G: 0.9599 \\ \n",
      "Epoch : [164/1000] \\ Loss D: 0.5977  \\ Loss G: 1.2692 \\ \n",
      "Epoch : [165/1000] \\ Loss D: 0.5355  \\ Loss G: 1.0062 \\ \n",
      "Epoch : [166/1000] \\ Loss D: 0.6705  \\ Loss G: 1.1535 \\ \n",
      "Epoch : [167/1000] \\ Loss D: 0.5000  \\ Loss G: 1.0797 \\ \n",
      "Epoch : [168/1000] \\ Loss D: 0.6765  \\ Loss G: 1.0280 \\ \n",
      "Epoch : [169/1000] \\ Loss D: 0.5666  \\ Loss G: 1.2000 \\ \n",
      "Epoch : [170/1000] \\ Loss D: 0.6175  \\ Loss G: 1.1944 \\ \n",
      "Epoch : [171/1000] \\ Loss D: 0.6067  \\ Loss G: 1.1517 \\ \n",
      "Epoch : [172/1000] \\ Loss D: 0.6767  \\ Loss G: 0.8766 \\ \n",
      "Epoch : [173/1000] \\ Loss D: 0.6402  \\ Loss G: 1.2704 \\ \n",
      "Epoch : [174/1000] \\ Loss D: 0.5781  \\ Loss G: 1.0921 \\ \n",
      "Epoch : [175/1000] \\ Loss D: 0.5860  \\ Loss G: 1.0577 \\ \n",
      "Epoch : [176/1000] \\ Loss D: 0.5614  \\ Loss G: 1.1641 \\ \n",
      "Epoch : [177/1000] \\ Loss D: 0.5815  \\ Loss G: 0.9808 \\ \n",
      "Epoch : [178/1000] \\ Loss D: 0.6098  \\ Loss G: 0.9993 \\ \n",
      "Epoch : [179/1000] \\ Loss D: 0.5861  \\ Loss G: 1.0622 \\ \n",
      "Epoch : [180/1000] \\ Loss D: 0.5531  \\ Loss G: 1.2396 \\ \n",
      "Epoch : [181/1000] \\ Loss D: 0.5167  \\ Loss G: 1.1512 \\ \n",
      "Epoch : [182/1000] \\ Loss D: 0.6286  \\ Loss G: 1.1196 \\ \n",
      "Epoch : [183/1000] \\ Loss D: 0.6052  \\ Loss G: 1.2208 \\ \n",
      "Epoch : [184/1000] \\ Loss D: 0.5978  \\ Loss G: 0.7788 \\ \n",
      "Epoch : [185/1000] \\ Loss D: 0.5948  \\ Loss G: 1.0183 \\ \n",
      "Epoch : [186/1000] \\ Loss D: 0.5333  \\ Loss G: 1.1631 \\ \n",
      "Epoch : [187/1000] \\ Loss D: 0.5669  \\ Loss G: 0.9236 \\ \n",
      "Epoch : [188/1000] \\ Loss D: 0.5573  \\ Loss G: 1.3172 \\ \n",
      "Epoch : [189/1000] \\ Loss D: 0.5273  \\ Loss G: 0.9963 \\ \n",
      "Epoch : [190/1000] \\ Loss D: 0.5662  \\ Loss G: 1.0015 \\ \n",
      "Epoch : [191/1000] \\ Loss D: 0.6326  \\ Loss G: 0.9809 \\ \n",
      "Epoch : [192/1000] \\ Loss D: 0.6500  \\ Loss G: 0.9734 \\ \n",
      "Epoch : [193/1000] \\ Loss D: 0.5823  \\ Loss G: 0.8943 \\ \n",
      "Epoch : [194/1000] \\ Loss D: 0.4942  \\ Loss G: 1.3031 \\ \n",
      "Epoch : [195/1000] \\ Loss D: 0.5127  \\ Loss G: 1.2311 \\ \n",
      "Epoch : [196/1000] \\ Loss D: 0.5933  \\ Loss G: 1.2141 \\ \n",
      "Epoch : [197/1000] \\ Loss D: 0.6343  \\ Loss G: 1.0735 \\ \n",
      "Epoch : [198/1000] \\ Loss D: 0.6732  \\ Loss G: 0.8882 \\ \n",
      "Epoch : [199/1000] \\ Loss D: 0.5255  \\ Loss G: 1.0060 \\ \n",
      "Epoch : [200/1000] \\ Loss D: 0.5905  \\ Loss G: 1.0992 \\ \n",
      "Epoch : [201/1000] \\ Loss D: 0.5876  \\ Loss G: 1.2194 \\ \n",
      "Epoch : [202/1000] \\ Loss D: 0.6974  \\ Loss G: 0.8721 \\ \n",
      "Epoch : [203/1000] \\ Loss D: 0.6619  \\ Loss G: 1.1206 \\ \n",
      "Epoch : [204/1000] \\ Loss D: 0.5066  \\ Loss G: 1.4733 \\ \n",
      "Epoch : [205/1000] \\ Loss D: 0.6111  \\ Loss G: 0.9916 \\ \n",
      "Epoch : [206/1000] \\ Loss D: 0.6237  \\ Loss G: 0.8182 \\ \n",
      "Epoch : [207/1000] \\ Loss D: 0.5720  \\ Loss G: 1.3143 \\ \n",
      "Epoch : [208/1000] \\ Loss D: 0.6708  \\ Loss G: 0.8667 \\ \n",
      "Epoch : [209/1000] \\ Loss D: 0.6259  \\ Loss G: 1.0908 \\ \n",
      "Epoch : [210/1000] \\ Loss D: 0.7354  \\ Loss G: 1.0462 \\ \n",
      "Epoch : [211/1000] \\ Loss D: 0.5802  \\ Loss G: 1.1457 \\ \n",
      "Epoch : [212/1000] \\ Loss D: 0.5277  \\ Loss G: 1.2066 \\ \n",
      "Epoch : [213/1000] \\ Loss D: 0.7129  \\ Loss G: 0.9847 \\ \n",
      "Epoch : [214/1000] \\ Loss D: 0.4918  \\ Loss G: 1.4009 \\ \n",
      "Epoch : [215/1000] \\ Loss D: 0.5675  \\ Loss G: 1.0318 \\ \n",
      "Epoch : [216/1000] \\ Loss D: 0.6170  \\ Loss G: 1.2681 \\ \n",
      "Epoch : [217/1000] \\ Loss D: 0.5482  \\ Loss G: 1.3161 \\ \n",
      "Epoch : [218/1000] \\ Loss D: 0.4622  \\ Loss G: 1.4990 \\ \n",
      "Epoch : [219/1000] \\ Loss D: 0.5593  \\ Loss G: 1.2280 \\ \n",
      "Epoch : [220/1000] \\ Loss D: 0.6498  \\ Loss G: 0.8275 \\ \n",
      "Epoch : [221/1000] \\ Loss D: 0.6404  \\ Loss G: 0.9440 \\ \n",
      "Epoch : [222/1000] \\ Loss D: 0.5606  \\ Loss G: 1.1410 \\ \n",
      "Epoch : [223/1000] \\ Loss D: 0.4673  \\ Loss G: 1.3789 \\ \n",
      "Epoch : [224/1000] \\ Loss D: 0.5850  \\ Loss G: 1.2646 \\ \n",
      "Epoch : [225/1000] \\ Loss D: 0.5656  \\ Loss G: 1.2598 \\ \n",
      "Epoch : [226/1000] \\ Loss D: 0.6645  \\ Loss G: 1.0575 \\ \n",
      "Epoch : [227/1000] \\ Loss D: 0.5747  \\ Loss G: 1.1621 \\ \n",
      "Epoch : [228/1000] \\ Loss D: 0.6377  \\ Loss G: 1.1642 \\ \n",
      "Epoch : [229/1000] \\ Loss D: 0.5191  \\ Loss G: 1.0684 \\ \n",
      "Epoch : [230/1000] \\ Loss D: 0.6283  \\ Loss G: 1.0229 \\ \n",
      "Epoch : [231/1000] \\ Loss D: 0.6030  \\ Loss G: 1.0149 \\ \n",
      "Epoch : [232/1000] \\ Loss D: 0.5875  \\ Loss G: 1.0384 \\ \n",
      "Epoch : [233/1000] \\ Loss D: 0.5668  \\ Loss G: 1.2380 \\ \n",
      "Epoch : [234/1000] \\ Loss D: 0.5505  \\ Loss G: 1.3413 \\ \n",
      "Epoch : [235/1000] \\ Loss D: 0.4985  \\ Loss G: 1.2363 \\ \n",
      "Epoch : [236/1000] \\ Loss D: 0.5788  \\ Loss G: 1.0991 \\ \n",
      "Epoch : [237/1000] \\ Loss D: 0.4603  \\ Loss G: 1.0038 \\ \n",
      "Epoch : [238/1000] \\ Loss D: 0.5104  \\ Loss G: 1.1799 \\ \n",
      "Epoch : [239/1000] \\ Loss D: 0.5708  \\ Loss G: 1.0587 \\ \n",
      "Epoch : [240/1000] \\ Loss D: 0.6748  \\ Loss G: 1.0482 \\ \n",
      "Epoch : [241/1000] \\ Loss D: 0.5292  \\ Loss G: 1.0447 \\ \n",
      "Epoch : [242/1000] \\ Loss D: 0.5787  \\ Loss G: 1.1655 \\ \n",
      "Epoch : [243/1000] \\ Loss D: 0.6219  \\ Loss G: 0.8191 \\ \n",
      "Epoch : [244/1000] \\ Loss D: 0.5616  \\ Loss G: 1.1695 \\ \n",
      "Epoch : [245/1000] \\ Loss D: 0.4722  \\ Loss G: 1.2823 \\ \n",
      "Epoch : [246/1000] \\ Loss D: 0.5092  \\ Loss G: 1.1379 \\ \n",
      "Epoch : [247/1000] \\ Loss D: 0.5485  \\ Loss G: 1.1851 \\ \n",
      "Epoch : [248/1000] \\ Loss D: 0.4729  \\ Loss G: 1.3295 \\ \n",
      "Epoch : [249/1000] \\ Loss D: 0.5300  \\ Loss G: 1.1896 \\ \n",
      "Epoch : [250/1000] \\ Loss D: 0.5813  \\ Loss G: 1.1888 \\ \n",
      "Epoch : [251/1000] \\ Loss D: 0.5424  \\ Loss G: 1.0770 \\ \n",
      "Epoch : [252/1000] \\ Loss D: 0.6123  \\ Loss G: 1.0779 \\ \n",
      "Epoch : [253/1000] \\ Loss D: 0.5951  \\ Loss G: 1.0235 \\ \n",
      "Epoch : [254/1000] \\ Loss D: 0.5376  \\ Loss G: 1.2145 \\ \n",
      "Epoch : [255/1000] \\ Loss D: 0.4723  \\ Loss G: 1.3553 \\ \n",
      "Epoch : [256/1000] \\ Loss D: 0.5414  \\ Loss G: 1.1641 \\ \n",
      "Epoch : [257/1000] \\ Loss D: 0.5424  \\ Loss G: 1.2016 \\ \n",
      "Epoch : [258/1000] \\ Loss D: 0.5748  \\ Loss G: 1.0545 \\ \n",
      "Epoch : [259/1000] \\ Loss D: 0.5705  \\ Loss G: 1.0359 \\ \n",
      "Epoch : [260/1000] \\ Loss D: 0.6428  \\ Loss G: 1.1723 \\ \n",
      "Epoch : [261/1000] \\ Loss D: 0.6149  \\ Loss G: 1.2081 \\ \n",
      "Epoch : [262/1000] \\ Loss D: 0.5462  \\ Loss G: 1.1395 \\ \n",
      "Epoch : [263/1000] \\ Loss D: 0.5313  \\ Loss G: 1.1101 \\ \n",
      "Epoch : [264/1000] \\ Loss D: 0.5379  \\ Loss G: 1.1755 \\ \n",
      "Epoch : [265/1000] \\ Loss D: 0.5207  \\ Loss G: 1.2616 \\ \n",
      "Epoch : [266/1000] \\ Loss D: 0.6106  \\ Loss G: 1.2613 \\ \n",
      "Epoch : [267/1000] \\ Loss D: 0.5547  \\ Loss G: 1.2599 \\ \n",
      "Epoch : [268/1000] \\ Loss D: 0.5086  \\ Loss G: 1.4059 \\ \n",
      "Epoch : [269/1000] \\ Loss D: 0.5602  \\ Loss G: 1.1277 \\ \n",
      "Epoch : [270/1000] \\ Loss D: 0.5215  \\ Loss G: 1.2215 \\ \n",
      "Epoch : [271/1000] \\ Loss D: 0.6480  \\ Loss G: 1.1875 \\ \n",
      "Epoch : [272/1000] \\ Loss D: 0.5531  \\ Loss G: 1.1677 \\ \n",
      "Epoch : [273/1000] \\ Loss D: 0.5226  \\ Loss G: 1.0735 \\ \n",
      "Epoch : [274/1000] \\ Loss D: 0.5207  \\ Loss G: 1.4455 \\ \n",
      "Epoch : [275/1000] \\ Loss D: 0.5985  \\ Loss G: 1.1767 \\ \n",
      "Epoch : [276/1000] \\ Loss D: 0.5020  \\ Loss G: 1.1797 \\ \n",
      "Epoch : [277/1000] \\ Loss D: 0.5226  \\ Loss G: 1.4202 \\ \n",
      "Epoch : [278/1000] \\ Loss D: 0.5037  \\ Loss G: 1.2111 \\ \n",
      "Epoch : [279/1000] \\ Loss D: 0.6041  \\ Loss G: 0.9711 \\ \n",
      "Epoch : [280/1000] \\ Loss D: 0.5164  \\ Loss G: 1.2964 \\ \n",
      "Epoch : [281/1000] \\ Loss D: 0.5342  \\ Loss G: 1.1671 \\ \n",
      "Epoch : [282/1000] \\ Loss D: 0.5505  \\ Loss G: 1.0494 \\ \n",
      "Epoch : [283/1000] \\ Loss D: 0.5691  \\ Loss G: 1.1683 \\ \n",
      "Epoch : [284/1000] \\ Loss D: 0.5736  \\ Loss G: 1.2063 \\ \n",
      "Epoch : [285/1000] \\ Loss D: 0.6040  \\ Loss G: 1.0082 \\ \n",
      "Epoch : [286/1000] \\ Loss D: 0.6323  \\ Loss G: 1.2004 \\ \n",
      "Epoch : [287/1000] \\ Loss D: 0.6223  \\ Loss G: 1.0296 \\ \n",
      "Epoch : [288/1000] \\ Loss D: 0.5803  \\ Loss G: 1.3041 \\ \n",
      "Epoch : [289/1000] \\ Loss D: 0.4732  \\ Loss G: 1.3027 \\ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [290/1000] \\ Loss D: 0.6017  \\ Loss G: 0.8932 \\ \n",
      "Epoch : [291/1000] \\ Loss D: 0.5854  \\ Loss G: 1.0868 \\ \n",
      "Epoch : [292/1000] \\ Loss D: 0.5391  \\ Loss G: 1.2199 \\ \n",
      "Epoch : [293/1000] \\ Loss D: 0.6141  \\ Loss G: 1.2682 \\ \n",
      "Epoch : [294/1000] \\ Loss D: 0.5308  \\ Loss G: 1.1315 \\ \n",
      "Epoch : [295/1000] \\ Loss D: 0.5912  \\ Loss G: 0.9213 \\ \n",
      "Epoch : [296/1000] \\ Loss D: 0.6722  \\ Loss G: 0.9317 \\ \n",
      "Epoch : [297/1000] \\ Loss D: 0.5688  \\ Loss G: 1.1957 \\ \n",
      "Epoch : [298/1000] \\ Loss D: 0.5810  \\ Loss G: 1.3419 \\ \n",
      "Epoch : [299/1000] \\ Loss D: 0.5331  \\ Loss G: 1.0818 \\ \n",
      "Epoch : [300/1000] \\ Loss D: 0.5187  \\ Loss G: 1.1235 \\ \n",
      "Epoch : [301/1000] \\ Loss D: 0.4922  \\ Loss G: 1.3917 \\ \n",
      "Epoch : [302/1000] \\ Loss D: 0.5902  \\ Loss G: 1.1856 \\ \n",
      "Epoch : [303/1000] \\ Loss D: 0.6494  \\ Loss G: 1.0629 \\ \n",
      "Epoch : [304/1000] \\ Loss D: 0.4602  \\ Loss G: 1.1420 \\ \n",
      "Epoch : [305/1000] \\ Loss D: 0.4847  \\ Loss G: 1.3019 \\ \n",
      "Epoch : [306/1000] \\ Loss D: 0.5059  \\ Loss G: 1.3632 \\ \n",
      "Epoch : [307/1000] \\ Loss D: 0.5039  \\ Loss G: 1.1472 \\ \n",
      "Epoch : [308/1000] \\ Loss D: 0.4904  \\ Loss G: 1.1925 \\ \n",
      "Epoch : [309/1000] \\ Loss D: 0.4684  \\ Loss G: 1.3688 \\ \n",
      "Epoch : [310/1000] \\ Loss D: 0.5743  \\ Loss G: 1.2061 \\ \n",
      "Epoch : [311/1000] \\ Loss D: 0.5296  \\ Loss G: 1.1528 \\ \n",
      "Epoch : [312/1000] \\ Loss D: 0.5735  \\ Loss G: 1.3267 \\ \n",
      "Epoch : [313/1000] \\ Loss D: 0.6380  \\ Loss G: 0.8384 \\ \n",
      "Epoch : [314/1000] \\ Loss D: 0.5145  \\ Loss G: 1.2742 \\ \n",
      "Epoch : [315/1000] \\ Loss D: 0.4786  \\ Loss G: 1.0243 \\ \n",
      "Epoch : [316/1000] \\ Loss D: 0.5461  \\ Loss G: 1.2129 \\ \n",
      "Epoch : [317/1000] \\ Loss D: 0.5855  \\ Loss G: 1.2178 \\ \n",
      "Epoch : [318/1000] \\ Loss D: 0.5238  \\ Loss G: 1.2060 \\ \n",
      "Epoch : [319/1000] \\ Loss D: 0.5209  \\ Loss G: 1.2661 \\ \n",
      "Epoch : [320/1000] \\ Loss D: 0.4919  \\ Loss G: 1.1994 \\ \n",
      "Epoch : [321/1000] \\ Loss D: 0.5372  \\ Loss G: 1.2931 \\ \n",
      "Epoch : [322/1000] \\ Loss D: 0.5716  \\ Loss G: 1.3489 \\ \n",
      "Epoch : [323/1000] \\ Loss D: 0.5239  \\ Loss G: 1.0704 \\ \n",
      "Epoch : [324/1000] \\ Loss D: 0.5211  \\ Loss G: 1.2722 \\ \n",
      "Epoch : [325/1000] \\ Loss D: 0.6096  \\ Loss G: 1.0223 \\ \n",
      "Epoch : [326/1000] \\ Loss D: 0.6311  \\ Loss G: 1.3447 \\ \n",
      "Epoch : [327/1000] \\ Loss D: 0.4330  \\ Loss G: 1.3764 \\ \n",
      "Epoch : [328/1000] \\ Loss D: 0.5108  \\ Loss G: 1.2007 \\ \n",
      "Epoch : [329/1000] \\ Loss D: 0.5411  \\ Loss G: 1.1716 \\ \n",
      "Epoch : [330/1000] \\ Loss D: 0.4924  \\ Loss G: 1.3342 \\ \n",
      "Epoch : [331/1000] \\ Loss D: 0.5721  \\ Loss G: 1.1407 \\ \n",
      "Epoch : [332/1000] \\ Loss D: 0.6112  \\ Loss G: 1.1630 \\ \n",
      "Epoch : [333/1000] \\ Loss D: 0.4538  \\ Loss G: 1.3259 \\ \n",
      "Epoch : [334/1000] \\ Loss D: 0.5018  \\ Loss G: 1.2023 \\ \n",
      "Epoch : [335/1000] \\ Loss D: 0.6150  \\ Loss G: 1.2579 \\ \n",
      "Epoch : [336/1000] \\ Loss D: 0.5602  \\ Loss G: 1.0894 \\ \n",
      "Epoch : [337/1000] \\ Loss D: 0.5775  \\ Loss G: 0.9976 \\ \n",
      "Epoch : [338/1000] \\ Loss D: 0.4402  \\ Loss G: 1.4021 \\ \n",
      "Epoch : [339/1000] \\ Loss D: 0.5007  \\ Loss G: 1.1947 \\ \n",
      "Epoch : [340/1000] \\ Loss D: 0.5218  \\ Loss G: 1.2866 \\ \n",
      "Epoch : [341/1000] \\ Loss D: 0.5423  \\ Loss G: 1.1775 \\ \n",
      "Epoch : [342/1000] \\ Loss D: 0.5940  \\ Loss G: 1.2541 \\ \n",
      "Epoch : [343/1000] \\ Loss D: 0.4855  \\ Loss G: 1.3016 \\ \n",
      "Epoch : [344/1000] \\ Loss D: 0.5781  \\ Loss G: 1.3273 \\ \n",
      "Epoch : [345/1000] \\ Loss D: 0.5113  \\ Loss G: 1.1768 \\ \n",
      "Epoch : [346/1000] \\ Loss D: 0.5018  \\ Loss G: 1.4828 \\ \n",
      "Epoch : [347/1000] \\ Loss D: 0.4970  \\ Loss G: 1.2327 \\ \n",
      "Epoch : [348/1000] \\ Loss D: 0.5228  \\ Loss G: 1.4501 \\ \n",
      "Epoch : [349/1000] \\ Loss D: 0.5403  \\ Loss G: 1.2101 \\ \n",
      "Epoch : [350/1000] \\ Loss D: 0.4554  \\ Loss G: 1.5821 \\ \n",
      "Epoch : [351/1000] \\ Loss D: 0.4508  \\ Loss G: 1.6294 \\ \n",
      "Epoch : [352/1000] \\ Loss D: 0.4822  \\ Loss G: 1.0894 \\ \n",
      "Epoch : [353/1000] \\ Loss D: 0.5565  \\ Loss G: 1.0074 \\ \n",
      "Epoch : [354/1000] \\ Loss D: 0.4982  \\ Loss G: 1.2982 \\ \n",
      "Epoch : [355/1000] \\ Loss D: 0.5502  \\ Loss G: 1.2377 \\ \n",
      "Epoch : [356/1000] \\ Loss D: 0.5018  \\ Loss G: 1.3670 \\ \n",
      "Epoch : [357/1000] \\ Loss D: 0.5398  \\ Loss G: 1.3697 \\ \n",
      "Epoch : [358/1000] \\ Loss D: 0.5690  \\ Loss G: 1.2791 \\ \n",
      "Epoch : [359/1000] \\ Loss D: 0.6223  \\ Loss G: 1.1665 \\ \n",
      "Epoch : [360/1000] \\ Loss D: 0.4774  \\ Loss G: 1.5009 \\ \n",
      "Epoch : [361/1000] \\ Loss D: 0.4810  \\ Loss G: 1.1137 \\ \n",
      "Epoch : [362/1000] \\ Loss D: 0.4619  \\ Loss G: 1.2353 \\ \n",
      "Epoch : [363/1000] \\ Loss D: 0.4103  \\ Loss G: 1.4675 \\ \n",
      "Epoch : [364/1000] \\ Loss D: 0.4448  \\ Loss G: 1.3239 \\ \n",
      "Epoch : [365/1000] \\ Loss D: 0.5876  \\ Loss G: 1.3031 \\ \n",
      "Epoch : [366/1000] \\ Loss D: 0.5212  \\ Loss G: 1.3885 \\ \n",
      "Epoch : [367/1000] \\ Loss D: 0.5503  \\ Loss G: 1.1663 \\ \n",
      "Epoch : [368/1000] \\ Loss D: 0.5662  \\ Loss G: 1.1452 \\ \n",
      "Epoch : [369/1000] \\ Loss D: 0.6526  \\ Loss G: 0.8996 \\ \n",
      "Epoch : [370/1000] \\ Loss D: 0.4902  \\ Loss G: 1.4385 \\ \n",
      "Epoch : [371/1000] \\ Loss D: 0.5017  \\ Loss G: 1.2871 \\ \n",
      "Epoch : [372/1000] \\ Loss D: 0.6302  \\ Loss G: 1.6573 \\ \n",
      "Epoch : [373/1000] \\ Loss D: 0.4452  \\ Loss G: 1.4741 \\ \n",
      "Epoch : [374/1000] \\ Loss D: 0.4841  \\ Loss G: 1.3390 \\ \n",
      "Epoch : [375/1000] \\ Loss D: 0.5148  \\ Loss G: 1.4129 \\ \n",
      "Epoch : [376/1000] \\ Loss D: 0.5175  \\ Loss G: 1.4792 \\ \n",
      "Epoch : [377/1000] \\ Loss D: 0.5438  \\ Loss G: 1.2322 \\ \n",
      "Epoch : [378/1000] \\ Loss D: 0.5440  \\ Loss G: 1.0312 \\ \n",
      "Epoch : [379/1000] \\ Loss D: 0.5338  \\ Loss G: 1.1065 \\ \n",
      "Epoch : [380/1000] \\ Loss D: 0.6444  \\ Loss G: 1.2006 \\ \n",
      "Epoch : [381/1000] \\ Loss D: 0.5617  \\ Loss G: 1.4127 \\ \n",
      "Epoch : [382/1000] \\ Loss D: 0.6851  \\ Loss G: 1.0472 \\ \n",
      "Epoch : [383/1000] \\ Loss D: 0.4288  \\ Loss G: 1.2141 \\ \n",
      "Epoch : [384/1000] \\ Loss D: 0.4611  \\ Loss G: 1.3370 \\ \n",
      "Epoch : [385/1000] \\ Loss D: 0.5158  \\ Loss G: 1.3208 \\ \n",
      "Epoch : [386/1000] \\ Loss D: 0.4851  \\ Loss G: 1.5517 \\ \n",
      "Epoch : [387/1000] \\ Loss D: 0.5548  \\ Loss G: 1.2218 \\ \n",
      "Epoch : [388/1000] \\ Loss D: 0.5915  \\ Loss G: 1.1707 \\ \n",
      "Epoch : [389/1000] \\ Loss D: 0.6576  \\ Loss G: 1.0825 \\ \n",
      "Epoch : [390/1000] \\ Loss D: 0.5713  \\ Loss G: 1.1706 \\ \n",
      "Epoch : [391/1000] \\ Loss D: 0.5176  \\ Loss G: 1.3458 \\ \n",
      "Epoch : [392/1000] \\ Loss D: 0.5770  \\ Loss G: 1.1768 \\ \n",
      "Epoch : [393/1000] \\ Loss D: 0.4813  \\ Loss G: 1.7639 \\ \n",
      "Epoch : [394/1000] \\ Loss D: 0.5948  \\ Loss G: 1.0972 \\ \n",
      "Epoch : [395/1000] \\ Loss D: 0.6110  \\ Loss G: 1.1035 \\ \n",
      "Epoch : [396/1000] \\ Loss D: 0.5873  \\ Loss G: 1.1550 \\ \n",
      "Epoch : [397/1000] \\ Loss D: 0.4539  \\ Loss G: 1.1899 \\ \n",
      "Epoch : [398/1000] \\ Loss D: 0.4721  \\ Loss G: 1.3930 \\ \n",
      "Epoch : [399/1000] \\ Loss D: 0.5143  \\ Loss G: 1.2612 \\ \n",
      "Epoch : [400/1000] \\ Loss D: 0.5439  \\ Loss G: 1.3663 \\ \n",
      "Epoch : [401/1000] \\ Loss D: 0.5672  \\ Loss G: 1.4037 \\ \n",
      "Epoch : [402/1000] \\ Loss D: 0.5941  \\ Loss G: 1.3903 \\ \n",
      "Epoch : [403/1000] \\ Loss D: 0.6436  \\ Loss G: 0.9434 \\ \n",
      "Epoch : [404/1000] \\ Loss D: 0.5167  \\ Loss G: 1.3551 \\ \n",
      "Epoch : [405/1000] \\ Loss D: 0.6356  \\ Loss G: 1.5379 \\ \n",
      "Epoch : [406/1000] \\ Loss D: 0.5566  \\ Loss G: 1.1640 \\ \n",
      "Epoch : [407/1000] \\ Loss D: 0.4645  \\ Loss G: 1.2049 \\ \n",
      "Epoch : [408/1000] \\ Loss D: 0.6008  \\ Loss G: 1.1400 \\ \n",
      "Epoch : [409/1000] \\ Loss D: 0.4397  \\ Loss G: 1.7503 \\ \n",
      "Epoch : [410/1000] \\ Loss D: 0.4574  \\ Loss G: 1.6427 \\ \n",
      "Epoch : [411/1000] \\ Loss D: 0.5227  \\ Loss G: 1.3537 \\ \n",
      "Epoch : [412/1000] \\ Loss D: 0.5199  \\ Loss G: 1.1209 \\ \n",
      "Epoch : [413/1000] \\ Loss D: 0.5502  \\ Loss G: 1.3418 \\ \n",
      "Epoch : [414/1000] \\ Loss D: 0.3847  \\ Loss G: 1.6015 \\ \n",
      "Epoch : [415/1000] \\ Loss D: 0.6639  \\ Loss G: 1.3384 \\ \n",
      "Epoch : [416/1000] \\ Loss D: 0.4475  \\ Loss G: 1.2869 \\ \n",
      "Epoch : [417/1000] \\ Loss D: 0.5661  \\ Loss G: 1.0582 \\ \n",
      "Epoch : [418/1000] \\ Loss D: 0.5100  \\ Loss G: 1.3774 \\ \n",
      "Epoch : [419/1000] \\ Loss D: 0.4154  \\ Loss G: 1.8970 \\ \n",
      "Epoch : [420/1000] \\ Loss D: 0.4686  \\ Loss G: 1.3543 \\ \n",
      "Epoch : [421/1000] \\ Loss D: 0.5753  \\ Loss G: 1.3391 \\ \n",
      "Epoch : [422/1000] \\ Loss D: 0.4941  \\ Loss G: 1.5095 \\ \n",
      "Epoch : [423/1000] \\ Loss D: 0.5284  \\ Loss G: 1.2600 \\ \n",
      "Epoch : [424/1000] \\ Loss D: 0.6367  \\ Loss G: 1.1599 \\ \n",
      "Epoch : [425/1000] \\ Loss D: 0.5533  \\ Loss G: 1.1769 \\ \n",
      "Epoch : [426/1000] \\ Loss D: 0.4999  \\ Loss G: 1.3293 \\ \n",
      "Epoch : [427/1000] \\ Loss D: 0.5264  \\ Loss G: 1.7354 \\ \n",
      "Epoch : [428/1000] \\ Loss D: 0.4972  \\ Loss G: 1.4729 \\ \n",
      "Epoch : [429/1000] \\ Loss D: 0.4989  \\ Loss G: 1.7291 \\ \n",
      "Epoch : [430/1000] \\ Loss D: 0.5282  \\ Loss G: 1.2182 \\ \n",
      "Epoch : [431/1000] \\ Loss D: 0.4760  \\ Loss G: 1.3998 \\ \n",
      "Epoch : [432/1000] \\ Loss D: 0.5409  \\ Loss G: 1.2453 \\ \n",
      "Epoch : [433/1000] \\ Loss D: 0.5288  \\ Loss G: 1.0997 \\ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [434/1000] \\ Loss D: 0.5250  \\ Loss G: 1.3178 \\ \n",
      "Epoch : [435/1000] \\ Loss D: 0.5073  \\ Loss G: 1.4110 \\ \n",
      "Epoch : [436/1000] \\ Loss D: 0.4483  \\ Loss G: 1.4062 \\ \n",
      "Epoch : [437/1000] \\ Loss D: 0.4446  \\ Loss G: 1.4463 \\ \n",
      "Epoch : [438/1000] \\ Loss D: 0.4206  \\ Loss G: 1.4066 \\ \n",
      "Epoch : [439/1000] \\ Loss D: 0.5492  \\ Loss G: 1.4511 \\ \n",
      "Epoch : [440/1000] \\ Loss D: 0.5118  \\ Loss G: 1.2709 \\ \n",
      "Epoch : [441/1000] \\ Loss D: 0.4434  \\ Loss G: 1.7471 \\ \n",
      "Epoch : [442/1000] \\ Loss D: 0.5636  \\ Loss G: 1.5565 \\ \n",
      "Epoch : [443/1000] \\ Loss D: 0.5781  \\ Loss G: 0.9278 \\ \n",
      "Epoch : [444/1000] \\ Loss D: 0.5017  \\ Loss G: 1.1981 \\ \n",
      "Epoch : [445/1000] \\ Loss D: 0.4876  \\ Loss G: 1.1783 \\ \n",
      "Epoch : [446/1000] \\ Loss D: 0.4645  \\ Loss G: 1.1922 \\ \n",
      "Epoch : [447/1000] \\ Loss D: 0.5768  \\ Loss G: 1.2137 \\ \n",
      "Epoch : [448/1000] \\ Loss D: 0.5229  \\ Loss G: 1.2149 \\ \n",
      "Epoch : [449/1000] \\ Loss D: 0.4681  \\ Loss G: 1.3242 \\ \n",
      "Epoch : [450/1000] \\ Loss D: 0.4257  \\ Loss G: 1.5953 \\ \n",
      "Epoch : [451/1000] \\ Loss D: 0.6059  \\ Loss G: 1.3474 \\ \n",
      "Epoch : [452/1000] \\ Loss D: 0.4738  \\ Loss G: 1.0399 \\ \n",
      "Epoch : [453/1000] \\ Loss D: 0.5041  \\ Loss G: 1.2506 \\ \n",
      "Epoch : [454/1000] \\ Loss D: 0.4839  \\ Loss G: 1.1723 \\ \n",
      "Epoch : [455/1000] \\ Loss D: 0.5080  \\ Loss G: 1.6914 \\ \n",
      "Epoch : [456/1000] \\ Loss D: 0.5360  \\ Loss G: 1.2705 \\ \n",
      "Epoch : [457/1000] \\ Loss D: 0.5364  \\ Loss G: 1.4271 \\ \n",
      "Epoch : [458/1000] \\ Loss D: 0.4706  \\ Loss G: 1.1711 \\ \n",
      "Epoch : [459/1000] \\ Loss D: 0.5683  \\ Loss G: 1.0401 \\ \n",
      "Epoch : [460/1000] \\ Loss D: 0.6717  \\ Loss G: 1.3176 \\ \n",
      "Epoch : [461/1000] \\ Loss D: 0.4539  \\ Loss G: 1.5117 \\ \n",
      "Epoch : [462/1000] \\ Loss D: 0.5016  \\ Loss G: 1.4694 \\ \n",
      "Epoch : [463/1000] \\ Loss D: 0.5236  \\ Loss G: 1.0741 \\ \n",
      "Epoch : [464/1000] \\ Loss D: 0.5721  \\ Loss G: 1.4258 \\ \n",
      "Epoch : [465/1000] \\ Loss D: 0.5726  \\ Loss G: 1.3823 \\ \n",
      "Epoch : [466/1000] \\ Loss D: 0.4769  \\ Loss G: 1.3979 \\ \n",
      "Epoch : [467/1000] \\ Loss D: 0.5682  \\ Loss G: 1.3808 \\ \n",
      "Epoch : [468/1000] \\ Loss D: 0.5452  \\ Loss G: 1.1960 \\ \n",
      "Epoch : [469/1000] \\ Loss D: 0.4084  \\ Loss G: 1.3540 \\ \n",
      "Epoch : [470/1000] \\ Loss D: 0.4785  \\ Loss G: 1.2922 \\ \n",
      "Epoch : [471/1000] \\ Loss D: 0.5778  \\ Loss G: 1.1608 \\ \n",
      "Epoch : [472/1000] \\ Loss D: 0.5282  \\ Loss G: 1.2251 \\ \n",
      "Epoch : [473/1000] \\ Loss D: 0.4954  \\ Loss G: 1.3493 \\ \n",
      "Epoch : [474/1000] \\ Loss D: 0.5672  \\ Loss G: 1.1679 \\ \n",
      "Epoch : [475/1000] \\ Loss D: 0.4705  \\ Loss G: 1.8949 \\ \n",
      "Epoch : [476/1000] \\ Loss D: 0.4878  \\ Loss G: 1.3725 \\ \n",
      "Epoch : [477/1000] \\ Loss D: 0.5116  \\ Loss G: 1.2380 \\ \n",
      "Epoch : [478/1000] \\ Loss D: 0.5377  \\ Loss G: 1.3106 \\ \n",
      "Epoch : [479/1000] \\ Loss D: 0.5177  \\ Loss G: 1.3266 \\ \n",
      "Epoch : [480/1000] \\ Loss D: 0.5415  \\ Loss G: 1.3284 \\ \n",
      "Epoch : [481/1000] \\ Loss D: 0.4023  \\ Loss G: 1.9546 \\ \n",
      "Epoch : [482/1000] \\ Loss D: 0.5401  \\ Loss G: 1.4579 \\ \n",
      "Epoch : [483/1000] \\ Loss D: 0.5290  \\ Loss G: 1.3295 \\ \n",
      "Epoch : [484/1000] \\ Loss D: 0.6000  \\ Loss G: 1.3441 \\ \n",
      "Epoch : [485/1000] \\ Loss D: 0.5324  \\ Loss G: 1.5076 \\ \n",
      "Epoch : [486/1000] \\ Loss D: 0.5308  \\ Loss G: 1.1915 \\ \n",
      "Epoch : [487/1000] \\ Loss D: 0.5077  \\ Loss G: 1.2800 \\ \n",
      "Epoch : [488/1000] \\ Loss D: 0.5648  \\ Loss G: 1.6398 \\ \n",
      "Epoch : [489/1000] \\ Loss D: 0.5169  \\ Loss G: 1.6259 \\ \n",
      "Epoch : [490/1000] \\ Loss D: 0.4571  \\ Loss G: 1.4828 \\ \n",
      "Epoch : [491/1000] \\ Loss D: 0.4973  \\ Loss G: 1.2964 \\ \n",
      "Epoch : [492/1000] \\ Loss D: 0.4096  \\ Loss G: 1.3848 \\ \n",
      "Epoch : [493/1000] \\ Loss D: 0.3840  \\ Loss G: 1.4892 \\ \n",
      "Epoch : [494/1000] \\ Loss D: 0.4056  \\ Loss G: 1.8171 \\ \n",
      "Epoch : [495/1000] \\ Loss D: 0.4917  \\ Loss G: 1.3595 \\ \n",
      "Epoch : [496/1000] \\ Loss D: 0.4647  \\ Loss G: 1.6627 \\ \n",
      "Epoch : [497/1000] \\ Loss D: 0.5362  \\ Loss G: 1.2872 \\ \n",
      "Epoch : [498/1000] \\ Loss D: 0.5093  \\ Loss G: 1.3147 \\ \n",
      "Epoch : [499/1000] \\ Loss D: 0.5029  \\ Loss G: 1.0467 \\ \n",
      "Epoch : [500/1000] \\ Loss D: 0.4670  \\ Loss G: 1.5375 \\ \n",
      "Epoch : [501/1000] \\ Loss D: 0.4884  \\ Loss G: 1.4525 \\ \n",
      "Epoch : [502/1000] \\ Loss D: 0.4662  \\ Loss G: 1.4370 \\ \n",
      "Epoch : [503/1000] \\ Loss D: 0.4684  \\ Loss G: 1.4930 \\ \n",
      "Epoch : [504/1000] \\ Loss D: 0.3564  \\ Loss G: 1.5264 \\ \n",
      "Epoch : [505/1000] \\ Loss D: 0.4518  \\ Loss G: 2.0733 \\ \n",
      "Epoch : [506/1000] \\ Loss D: 0.5753  \\ Loss G: 1.3440 \\ \n",
      "Epoch : [507/1000] \\ Loss D: 0.3940  \\ Loss G: 1.5566 \\ \n",
      "Epoch : [508/1000] \\ Loss D: 0.5381  \\ Loss G: 1.7484 \\ \n",
      "Epoch : [509/1000] \\ Loss D: 0.4570  \\ Loss G: 1.4497 \\ \n",
      "Epoch : [510/1000] \\ Loss D: 0.4356  \\ Loss G: 1.1876 \\ \n",
      "Epoch : [511/1000] \\ Loss D: 0.5245  \\ Loss G: 1.0123 \\ \n",
      "Epoch : [512/1000] \\ Loss D: 0.6297  \\ Loss G: 1.4142 \\ \n",
      "Epoch : [513/1000] \\ Loss D: 0.5111  \\ Loss G: 1.5414 \\ \n",
      "Epoch : [514/1000] \\ Loss D: 0.4155  \\ Loss G: 1.5000 \\ \n",
      "Epoch : [515/1000] \\ Loss D: 0.5924  \\ Loss G: 1.2921 \\ \n",
      "Epoch : [516/1000] \\ Loss D: 0.4167  \\ Loss G: 1.7050 \\ \n",
      "Epoch : [517/1000] \\ Loss D: 0.4465  \\ Loss G: 1.6658 \\ \n",
      "Epoch : [518/1000] \\ Loss D: 0.5862  \\ Loss G: 1.4538 \\ \n",
      "Epoch : [519/1000] \\ Loss D: 0.5223  \\ Loss G: 1.5530 \\ \n",
      "Epoch : [520/1000] \\ Loss D: 0.5795  \\ Loss G: 1.3400 \\ \n",
      "Epoch : [521/1000] \\ Loss D: 0.5376  \\ Loss G: 1.4112 \\ \n",
      "Epoch : [522/1000] \\ Loss D: 0.5035  \\ Loss G: 1.2291 \\ \n",
      "Epoch : [523/1000] \\ Loss D: 0.5547  \\ Loss G: 1.1272 \\ \n",
      "Epoch : [524/1000] \\ Loss D: 0.4439  \\ Loss G: 1.5166 \\ \n",
      "Epoch : [525/1000] \\ Loss D: 0.5892  \\ Loss G: 1.4852 \\ \n",
      "Epoch : [526/1000] \\ Loss D: 0.6064  \\ Loss G: 1.5160 \\ \n",
      "Epoch : [527/1000] \\ Loss D: 0.5660  \\ Loss G: 0.9927 \\ \n",
      "Epoch : [528/1000] \\ Loss D: 0.5969  \\ Loss G: 1.1854 \\ \n",
      "Epoch : [529/1000] \\ Loss D: 0.5366  \\ Loss G: 1.2117 \\ \n",
      "Epoch : [530/1000] \\ Loss D: 0.3981  \\ Loss G: 1.2214 \\ \n",
      "Epoch : [531/1000] \\ Loss D: 0.4544  \\ Loss G: 1.3661 \\ \n",
      "Epoch : [532/1000] \\ Loss D: 0.5382  \\ Loss G: 1.3288 \\ \n",
      "Epoch : [533/1000] \\ Loss D: 0.5384  \\ Loss G: 1.1114 \\ \n",
      "Epoch : [534/1000] \\ Loss D: 0.5293  \\ Loss G: 1.2417 \\ \n",
      "Epoch : [535/1000] \\ Loss D: 0.4741  \\ Loss G: 1.5135 \\ \n",
      "Epoch : [536/1000] \\ Loss D: 0.4834  \\ Loss G: 1.2740 \\ \n",
      "Epoch : [537/1000] \\ Loss D: 0.5094  \\ Loss G: 1.1665 \\ \n",
      "Epoch : [538/1000] \\ Loss D: 0.6116  \\ Loss G: 1.1465 \\ \n",
      "Epoch : [539/1000] \\ Loss D: 0.5316  \\ Loss G: 1.4388 \\ \n",
      "Epoch : [540/1000] \\ Loss D: 0.5642  \\ Loss G: 1.3396 \\ \n",
      "Epoch : [541/1000] \\ Loss D: 0.5823  \\ Loss G: 1.5548 \\ \n",
      "Epoch : [542/1000] \\ Loss D: 0.4847  \\ Loss G: 1.4526 \\ \n",
      "Epoch : [543/1000] \\ Loss D: 0.5660  \\ Loss G: 1.2808 \\ \n",
      "Epoch : [544/1000] \\ Loss D: 0.4353  \\ Loss G: 1.8093 \\ \n",
      "Epoch : [545/1000] \\ Loss D: 0.5337  \\ Loss G: 1.3849 \\ \n",
      "Epoch : [546/1000] \\ Loss D: 0.4402  \\ Loss G: 1.5108 \\ \n",
      "Epoch : [547/1000] \\ Loss D: 0.4703  \\ Loss G: 1.4662 \\ \n",
      "Epoch : [548/1000] \\ Loss D: 0.5590  \\ Loss G: 1.1445 \\ \n",
      "Epoch : [549/1000] \\ Loss D: 0.4231  \\ Loss G: 1.8189 \\ \n",
      "Epoch : [550/1000] \\ Loss D: 0.5315  \\ Loss G: 1.5827 \\ \n",
      "Epoch : [551/1000] \\ Loss D: 0.5854  \\ Loss G: 1.4751 \\ \n",
      "Epoch : [552/1000] \\ Loss D: 0.5964  \\ Loss G: 1.6817 \\ \n",
      "Epoch : [553/1000] \\ Loss D: 0.5336  \\ Loss G: 1.4416 \\ \n",
      "Epoch : [554/1000] \\ Loss D: 0.4455  \\ Loss G: 1.6147 \\ \n",
      "Epoch : [555/1000] \\ Loss D: 0.4792  \\ Loss G: 1.4426 \\ \n",
      "Epoch : [556/1000] \\ Loss D: 0.5112  \\ Loss G: 1.1842 \\ \n",
      "Epoch : [557/1000] \\ Loss D: 0.5579  \\ Loss G: 1.3417 \\ \n",
      "Epoch : [558/1000] \\ Loss D: 0.4461  \\ Loss G: 1.6396 \\ \n",
      "Epoch : [559/1000] \\ Loss D: 0.4403  \\ Loss G: 1.3487 \\ \n",
      "Epoch : [560/1000] \\ Loss D: 0.5638  \\ Loss G: 1.3712 \\ \n",
      "Epoch : [561/1000] \\ Loss D: 0.5275  \\ Loss G: 1.4621 \\ \n",
      "Epoch : [562/1000] \\ Loss D: 0.5175  \\ Loss G: 1.3389 \\ \n",
      "Epoch : [563/1000] \\ Loss D: 0.5469  \\ Loss G: 1.3858 \\ \n",
      "Epoch : [564/1000] \\ Loss D: 0.5207  \\ Loss G: 1.5014 \\ \n",
      "Epoch : [565/1000] \\ Loss D: 0.3678  \\ Loss G: 1.6349 \\ \n",
      "Epoch : [566/1000] \\ Loss D: 0.5017  \\ Loss G: 1.5492 \\ \n",
      "Epoch : [567/1000] \\ Loss D: 0.5218  \\ Loss G: 1.4799 \\ \n",
      "Epoch : [568/1000] \\ Loss D: 0.4640  \\ Loss G: 1.2990 \\ \n",
      "Epoch : [569/1000] \\ Loss D: 0.4820  \\ Loss G: 1.5732 \\ \n",
      "Epoch : [570/1000] \\ Loss D: 0.5188  \\ Loss G: 1.6570 \\ \n",
      "Epoch : [571/1000] \\ Loss D: 0.4927  \\ Loss G: 1.5367 \\ \n",
      "Epoch : [572/1000] \\ Loss D: 0.4210  \\ Loss G: 1.4763 \\ \n",
      "Epoch : [573/1000] \\ Loss D: 0.4613  \\ Loss G: 1.5106 \\ \n",
      "Epoch : [574/1000] \\ Loss D: 0.4821  \\ Loss G: 2.0732 \\ \n",
      "Epoch : [575/1000] \\ Loss D: 0.4045  \\ Loss G: 1.7245 \\ \n",
      "Epoch : [576/1000] \\ Loss D: 0.4808  \\ Loss G: 1.6608 \\ \n",
      "Epoch : [577/1000] \\ Loss D: 0.5182  \\ Loss G: 0.9938 \\ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [578/1000] \\ Loss D: 0.5201  \\ Loss G: 1.0241 \\ \n",
      "Epoch : [579/1000] \\ Loss D: 0.5427  \\ Loss G: 1.5439 \\ \n",
      "Epoch : [580/1000] \\ Loss D: 0.6180  \\ Loss G: 1.2656 \\ \n",
      "Epoch : [581/1000] \\ Loss D: 0.4279  \\ Loss G: 1.2793 \\ \n",
      "Epoch : [582/1000] \\ Loss D: 0.4714  \\ Loss G: 1.2913 \\ \n",
      "Epoch : [583/1000] \\ Loss D: 0.4898  \\ Loss G: 1.2731 \\ \n",
      "Epoch : [584/1000] \\ Loss D: 0.5201  \\ Loss G: 1.5430 \\ \n",
      "Epoch : [585/1000] \\ Loss D: 0.5418  \\ Loss G: 1.1567 \\ \n",
      "Epoch : [586/1000] \\ Loss D: 0.4305  \\ Loss G: 1.7331 \\ \n",
      "Epoch : [587/1000] \\ Loss D: 0.5292  \\ Loss G: 1.1586 \\ \n",
      "Epoch : [588/1000] \\ Loss D: 0.6296  \\ Loss G: 1.1192 \\ \n",
      "Epoch : [589/1000] \\ Loss D: 0.4912  \\ Loss G: 1.4215 \\ \n",
      "Epoch : [590/1000] \\ Loss D: 0.4252  \\ Loss G: 1.0206 \\ \n",
      "Epoch : [591/1000] \\ Loss D: 0.4799  \\ Loss G: 1.6162 \\ \n",
      "Epoch : [592/1000] \\ Loss D: 0.4550  \\ Loss G: 1.8657 \\ \n",
      "Epoch : [593/1000] \\ Loss D: 0.4972  \\ Loss G: 2.0385 \\ \n",
      "Epoch : [594/1000] \\ Loss D: 0.5105  \\ Loss G: 1.6713 \\ \n",
      "Epoch : [595/1000] \\ Loss D: 0.4687  \\ Loss G: 1.2882 \\ \n",
      "Epoch : [596/1000] \\ Loss D: 0.4552  \\ Loss G: 1.7920 \\ \n",
      "Epoch : [597/1000] \\ Loss D: 0.4055  \\ Loss G: 1.9615 \\ \n",
      "Epoch : [598/1000] \\ Loss D: 0.5044  \\ Loss G: 1.7030 \\ \n",
      "Epoch : [599/1000] \\ Loss D: 0.4079  \\ Loss G: 1.3413 \\ \n",
      "Epoch : [600/1000] \\ Loss D: 0.4435  \\ Loss G: 1.6315 \\ \n",
      "Epoch : [601/1000] \\ Loss D: 0.4537  \\ Loss G: 1.6987 \\ \n",
      "Epoch : [602/1000] \\ Loss D: 0.3187  \\ Loss G: 1.5810 \\ \n",
      "Epoch : [603/1000] \\ Loss D: 0.3296  \\ Loss G: 1.9532 \\ \n",
      "Epoch : [604/1000] \\ Loss D: 0.5321  \\ Loss G: 1.1902 \\ \n",
      "Epoch : [605/1000] \\ Loss D: 0.4454  \\ Loss G: 1.7418 \\ \n",
      "Epoch : [606/1000] \\ Loss D: 0.5558  \\ Loss G: 1.8781 \\ \n",
      "Epoch : [607/1000] \\ Loss D: 0.5292  \\ Loss G: 1.4132 \\ \n",
      "Epoch : [608/1000] \\ Loss D: 0.5359  \\ Loss G: 1.4765 \\ \n",
      "Epoch : [609/1000] \\ Loss D: 0.4484  \\ Loss G: 1.5988 \\ \n",
      "Epoch : [610/1000] \\ Loss D: 0.4822  \\ Loss G: 1.6977 \\ \n",
      "Epoch : [611/1000] \\ Loss D: 0.4806  \\ Loss G: 1.5441 \\ \n",
      "Epoch : [612/1000] \\ Loss D: 0.4280  \\ Loss G: 1.4584 \\ \n",
      "Epoch : [613/1000] \\ Loss D: 0.4283  \\ Loss G: 1.3194 \\ \n",
      "Epoch : [614/1000] \\ Loss D: 0.4494  \\ Loss G: 1.6900 \\ \n",
      "Epoch : [615/1000] \\ Loss D: 0.4798  \\ Loss G: 1.2415 \\ \n",
      "Epoch : [616/1000] \\ Loss D: 0.4910  \\ Loss G: 1.8000 \\ \n",
      "Epoch : [617/1000] \\ Loss D: 0.5114  \\ Loss G: 1.3712 \\ \n",
      "Epoch : [618/1000] \\ Loss D: 0.4394  \\ Loss G: 1.3961 \\ \n",
      "Epoch : [619/1000] \\ Loss D: 0.5342  \\ Loss G: 1.7027 \\ \n",
      "Epoch : [620/1000] \\ Loss D: 0.6022  \\ Loss G: 1.1771 \\ \n",
      "Epoch : [621/1000] \\ Loss D: 0.4916  \\ Loss G: 1.5629 \\ \n",
      "Epoch : [622/1000] \\ Loss D: 0.4686  \\ Loss G: 1.5428 \\ \n",
      "Epoch : [623/1000] \\ Loss D: 0.5181  \\ Loss G: 1.5047 \\ \n",
      "Epoch : [624/1000] \\ Loss D: 0.5012  \\ Loss G: 1.4739 \\ \n",
      "Epoch : [625/1000] \\ Loss D: 0.4927  \\ Loss G: 1.7698 \\ \n",
      "Epoch : [626/1000] \\ Loss D: 0.5169  \\ Loss G: 1.3152 \\ \n",
      "Epoch : [627/1000] \\ Loss D: 0.5357  \\ Loss G: 1.3084 \\ \n",
      "Epoch : [628/1000] \\ Loss D: 0.4859  \\ Loss G: 1.4976 \\ \n",
      "Epoch : [629/1000] \\ Loss D: 0.5184  \\ Loss G: 1.0871 \\ \n",
      "Epoch : [630/1000] \\ Loss D: 0.5540  \\ Loss G: 1.5882 \\ \n",
      "Epoch : [631/1000] \\ Loss D: 0.6696  \\ Loss G: 0.9128 \\ \n",
      "Epoch : [632/1000] \\ Loss D: 0.3987  \\ Loss G: 1.5980 \\ \n",
      "Epoch : [633/1000] \\ Loss D: 0.4781  \\ Loss G: 1.7531 \\ \n",
      "Epoch : [634/1000] \\ Loss D: 0.4575  \\ Loss G: 1.1362 \\ \n",
      "Epoch : [635/1000] \\ Loss D: 0.4868  \\ Loss G: 1.2385 \\ \n",
      "Epoch : [636/1000] \\ Loss D: 0.5098  \\ Loss G: 1.8218 \\ \n",
      "Epoch : [637/1000] \\ Loss D: 0.5931  \\ Loss G: 1.1784 \\ \n",
      "Epoch : [638/1000] \\ Loss D: 0.4786  \\ Loss G: 1.2594 \\ \n",
      "Epoch : [639/1000] \\ Loss D: 0.4324  \\ Loss G: 1.4361 \\ \n",
      "Epoch : [640/1000] \\ Loss D: 0.5252  \\ Loss G: 1.3925 \\ \n",
      "Epoch : [641/1000] \\ Loss D: 0.5000  \\ Loss G: 1.4707 \\ \n",
      "Epoch : [642/1000] \\ Loss D: 0.5775  \\ Loss G: 1.3671 \\ \n",
      "Epoch : [643/1000] \\ Loss D: 0.4767  \\ Loss G: 1.5651 \\ \n",
      "Epoch : [644/1000] \\ Loss D: 0.5015  \\ Loss G: 1.3702 \\ \n",
      "Epoch : [645/1000] \\ Loss D: 0.4648  \\ Loss G: 1.7371 \\ \n",
      "Epoch : [646/1000] \\ Loss D: 0.3873  \\ Loss G: 1.8087 \\ \n",
      "Epoch : [647/1000] \\ Loss D: 0.5195  \\ Loss G: 1.9273 \\ \n",
      "Epoch : [648/1000] \\ Loss D: 0.5486  \\ Loss G: 1.2700 \\ \n",
      "Epoch : [649/1000] \\ Loss D: 0.4818  \\ Loss G: 1.5596 \\ \n",
      "Epoch : [650/1000] \\ Loss D: 0.4054  \\ Loss G: 1.4011 \\ \n",
      "Epoch : [651/1000] \\ Loss D: 0.5153  \\ Loss G: 1.0989 \\ \n",
      "Epoch : [652/1000] \\ Loss D: 0.5193  \\ Loss G: 1.2686 \\ \n",
      "Epoch : [653/1000] \\ Loss D: 0.4912  \\ Loss G: 1.3014 \\ \n",
      "Epoch : [654/1000] \\ Loss D: 0.4608  \\ Loss G: 1.6672 \\ \n",
      "Epoch : [655/1000] \\ Loss D: 0.5294  \\ Loss G: 1.1959 \\ \n",
      "Epoch : [656/1000] \\ Loss D: 0.5252  \\ Loss G: 2.0411 \\ \n",
      "Epoch : [657/1000] \\ Loss D: 0.4672  \\ Loss G: 1.3117 \\ \n",
      "Epoch : [658/1000] \\ Loss D: 0.4605  \\ Loss G: 1.0965 \\ \n",
      "Epoch : [659/1000] \\ Loss D: 0.4604  \\ Loss G: 1.7357 \\ \n",
      "Epoch : [660/1000] \\ Loss D: 0.5203  \\ Loss G: 1.2902 \\ \n",
      "Epoch : [661/1000] \\ Loss D: 0.6158  \\ Loss G: 1.1469 \\ \n",
      "Epoch : [662/1000] \\ Loss D: 0.5355  \\ Loss G: 1.5147 \\ \n",
      "Epoch : [663/1000] \\ Loss D: 0.4411  \\ Loss G: 1.7762 \\ \n",
      "Epoch : [664/1000] \\ Loss D: 0.4906  \\ Loss G: 1.2026 \\ \n",
      "Epoch : [665/1000] \\ Loss D: 0.5128  \\ Loss G: 2.0345 \\ \n",
      "Epoch : [666/1000] \\ Loss D: 0.4965  \\ Loss G: 1.5150 \\ \n",
      "Epoch : [667/1000] \\ Loss D: 0.4555  \\ Loss G: 1.2656 \\ \n",
      "Epoch : [668/1000] \\ Loss D: 0.5298  \\ Loss G: 1.5294 \\ \n",
      "Epoch : [669/1000] \\ Loss D: 0.4987  \\ Loss G: 1.6475 \\ \n",
      "Epoch : [670/1000] \\ Loss D: 0.4165  \\ Loss G: 1.5378 \\ \n",
      "Epoch : [671/1000] \\ Loss D: 0.5201  \\ Loss G: 1.6734 \\ \n",
      "Epoch : [672/1000] \\ Loss D: 0.5344  \\ Loss G: 1.5873 \\ \n",
      "Epoch : [673/1000] \\ Loss D: 0.5365  \\ Loss G: 1.9388 \\ \n",
      "Epoch : [674/1000] \\ Loss D: 0.4821  \\ Loss G: 1.4435 \\ \n",
      "Epoch : [675/1000] \\ Loss D: 0.4436  \\ Loss G: 1.4288 \\ \n",
      "Epoch : [676/1000] \\ Loss D: 0.5856  \\ Loss G: 1.1986 \\ \n",
      "Epoch : [677/1000] \\ Loss D: 0.4522  \\ Loss G: 1.6418 \\ \n",
      "Epoch : [678/1000] \\ Loss D: 0.5094  \\ Loss G: 1.4843 \\ \n",
      "Epoch : [679/1000] \\ Loss D: 0.4825  \\ Loss G: 1.4282 \\ \n",
      "Epoch : [680/1000] \\ Loss D: 0.5573  \\ Loss G: 1.4567 \\ \n",
      "Epoch : [681/1000] \\ Loss D: 0.5264  \\ Loss G: 1.2795 \\ \n",
      "Epoch : [682/1000] \\ Loss D: 0.4554  \\ Loss G: 1.5466 \\ \n",
      "Epoch : [683/1000] \\ Loss D: 0.4004  \\ Loss G: 1.5689 \\ \n",
      "Epoch : [684/1000] \\ Loss D: 0.5149  \\ Loss G: 1.3013 \\ \n",
      "Epoch : [685/1000] \\ Loss D: 0.5921  \\ Loss G: 1.2692 \\ \n",
      "Epoch : [686/1000] \\ Loss D: 0.4565  \\ Loss G: 2.0145 \\ \n",
      "Epoch : [687/1000] \\ Loss D: 0.6571  \\ Loss G: 1.3431 \\ \n",
      "Epoch : [688/1000] \\ Loss D: 0.6046  \\ Loss G: 1.4130 \\ \n",
      "Epoch : [689/1000] \\ Loss D: 0.4799  \\ Loss G: 1.6080 \\ \n",
      "Epoch : [690/1000] \\ Loss D: 0.5533  \\ Loss G: 1.4892 \\ \n",
      "Epoch : [691/1000] \\ Loss D: 0.5652  \\ Loss G: 1.5313 \\ \n",
      "Epoch : [692/1000] \\ Loss D: 0.5559  \\ Loss G: 1.5604 \\ \n",
      "Epoch : [693/1000] \\ Loss D: 0.4885  \\ Loss G: 1.6293 \\ \n",
      "Epoch : [694/1000] \\ Loss D: 0.4710  \\ Loss G: 1.5997 \\ \n",
      "Epoch : [695/1000] \\ Loss D: 0.5386  \\ Loss G: 1.4539 \\ \n",
      "Epoch : [696/1000] \\ Loss D: 0.4808  \\ Loss G: 1.4647 \\ \n",
      "Epoch : [697/1000] \\ Loss D: 0.5731  \\ Loss G: 1.3958 \\ \n",
      "Epoch : [698/1000] \\ Loss D: 0.6270  \\ Loss G: 0.9939 \\ \n",
      "Epoch : [699/1000] \\ Loss D: 0.5286  \\ Loss G: 1.3465 \\ \n",
      "Epoch : [700/1000] \\ Loss D: 0.4394  \\ Loss G: 1.4434 \\ \n",
      "Epoch : [701/1000] \\ Loss D: 0.5958  \\ Loss G: 1.3789 \\ \n",
      "Epoch : [702/1000] \\ Loss D: 0.4833  \\ Loss G: 1.3937 \\ \n",
      "Epoch : [703/1000] \\ Loss D: 0.4759  \\ Loss G: 1.7296 \\ \n",
      "Epoch : [704/1000] \\ Loss D: 0.4492  \\ Loss G: 1.5703 \\ \n",
      "Epoch : [705/1000] \\ Loss D: 0.4736  \\ Loss G: 1.7661 \\ \n",
      "Epoch : [706/1000] \\ Loss D: 0.4623  \\ Loss G: 1.6282 \\ \n",
      "Epoch : [707/1000] \\ Loss D: 0.5123  \\ Loss G: 1.3854 \\ \n",
      "Epoch : [708/1000] \\ Loss D: 0.5291  \\ Loss G: 1.6096 \\ \n",
      "Epoch : [709/1000] \\ Loss D: 0.3967  \\ Loss G: 1.4915 \\ \n",
      "Epoch : [710/1000] \\ Loss D: 0.4743  \\ Loss G: 1.7770 \\ \n",
      "Epoch : [711/1000] \\ Loss D: 0.4018  \\ Loss G: 1.7759 \\ \n",
      "Epoch : [712/1000] \\ Loss D: 0.5504  \\ Loss G: 1.4599 \\ \n",
      "Epoch : [713/1000] \\ Loss D: 0.6033  \\ Loss G: 1.1484 \\ \n",
      "Epoch : [714/1000] \\ Loss D: 0.5349  \\ Loss G: 1.7066 \\ \n",
      "Epoch : [715/1000] \\ Loss D: 0.4012  \\ Loss G: 1.5087 \\ \n",
      "Epoch : [716/1000] \\ Loss D: 0.5514  \\ Loss G: 1.2842 \\ \n",
      "Epoch : [717/1000] \\ Loss D: 0.4734  \\ Loss G: 1.4583 \\ \n",
      "Epoch : [718/1000] \\ Loss D: 0.5924  \\ Loss G: 1.3261 \\ \n",
      "Epoch : [719/1000] \\ Loss D: 0.4589  \\ Loss G: 1.3865 \\ \n",
      "Epoch : [720/1000] \\ Loss D: 0.4556  \\ Loss G: 1.1910 \\ \n",
      "Epoch : [721/1000] \\ Loss D: 0.3918  \\ Loss G: 1.3257 \\ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [722/1000] \\ Loss D: 0.4202  \\ Loss G: 1.4312 \\ \n",
      "Epoch : [723/1000] \\ Loss D: 0.4361  \\ Loss G: 1.4704 \\ \n",
      "Epoch : [724/1000] \\ Loss D: 0.4880  \\ Loss G: 1.6378 \\ \n",
      "Epoch : [725/1000] \\ Loss D: 0.5191  \\ Loss G: 1.1589 \\ \n",
      "Epoch : [726/1000] \\ Loss D: 0.4729  \\ Loss G: 1.5633 \\ \n",
      "Epoch : [727/1000] \\ Loss D: 0.5828  \\ Loss G: 1.1614 \\ \n",
      "Epoch : [728/1000] \\ Loss D: 0.4650  \\ Loss G: 1.6202 \\ \n",
      "Epoch : [729/1000] \\ Loss D: 0.4277  \\ Loss G: 1.6252 \\ \n",
      "Epoch : [730/1000] \\ Loss D: 0.4476  \\ Loss G: 1.6321 \\ \n",
      "Epoch : [731/1000] \\ Loss D: 0.4163  \\ Loss G: 1.7379 \\ \n",
      "Epoch : [732/1000] \\ Loss D: 0.5576  \\ Loss G: 1.7156 \\ \n",
      "Epoch : [733/1000] \\ Loss D: 0.4562  \\ Loss G: 2.1098 \\ \n",
      "Epoch : [734/1000] \\ Loss D: 0.4387  \\ Loss G: 1.4456 \\ \n",
      "Epoch : [735/1000] \\ Loss D: 0.5003  \\ Loss G: 1.3187 \\ \n",
      "Epoch : [736/1000] \\ Loss D: 0.6256  \\ Loss G: 1.0567 \\ \n",
      "Epoch : [737/1000] \\ Loss D: 0.4556  \\ Loss G: 1.3100 \\ \n",
      "Epoch : [738/1000] \\ Loss D: 0.3947  \\ Loss G: 2.0153 \\ \n",
      "Epoch : [739/1000] \\ Loss D: 0.4804  \\ Loss G: 1.6806 \\ \n",
      "Epoch : [740/1000] \\ Loss D: 0.4814  \\ Loss G: 1.9263 \\ \n",
      "Epoch : [741/1000] \\ Loss D: 0.4318  \\ Loss G: 1.5968 \\ \n",
      "Epoch : [742/1000] \\ Loss D: 0.4278  \\ Loss G: 1.3881 \\ \n",
      "Epoch : [743/1000] \\ Loss D: 0.6132  \\ Loss G: 1.1732 \\ \n",
      "Epoch : [744/1000] \\ Loss D: 0.4981  \\ Loss G: 1.1980 \\ \n",
      "Epoch : [745/1000] \\ Loss D: 0.5177  \\ Loss G: 1.4819 \\ \n",
      "Epoch : [746/1000] \\ Loss D: 0.3897  \\ Loss G: 1.5878 \\ \n",
      "Epoch : [747/1000] \\ Loss D: 0.4556  \\ Loss G: 1.4101 \\ \n",
      "Epoch : [748/1000] \\ Loss D: 0.5753  \\ Loss G: 1.2403 \\ \n",
      "Epoch : [749/1000] \\ Loss D: 0.3767  \\ Loss G: 2.0851 \\ \n",
      "Epoch : [750/1000] \\ Loss D: 0.4378  \\ Loss G: 1.7280 \\ \n",
      "Epoch : [751/1000] \\ Loss D: 0.4607  \\ Loss G: 1.6795 \\ \n",
      "Epoch : [752/1000] \\ Loss D: 0.4915  \\ Loss G: 1.6662 \\ \n",
      "Epoch : [753/1000] \\ Loss D: 0.4679  \\ Loss G: 1.7319 \\ \n",
      "Epoch : [754/1000] \\ Loss D: 0.4342  \\ Loss G: 1.3424 \\ \n",
      "Epoch : [755/1000] \\ Loss D: 0.4491  \\ Loss G: 1.3908 \\ \n",
      "Epoch : [756/1000] \\ Loss D: 0.3751  \\ Loss G: 1.8467 \\ \n",
      "Epoch : [757/1000] \\ Loss D: 0.4628  \\ Loss G: 1.4412 \\ \n",
      "Epoch : [758/1000] \\ Loss D: 0.4834  \\ Loss G: 1.4481 \\ \n",
      "Epoch : [759/1000] \\ Loss D: 0.4139  \\ Loss G: 1.4490 \\ \n",
      "Epoch : [760/1000] \\ Loss D: 0.5729  \\ Loss G: 1.4200 \\ \n",
      "Epoch : [761/1000] \\ Loss D: 0.3797  \\ Loss G: 1.5904 \\ \n",
      "Epoch : [762/1000] \\ Loss D: 0.4421  \\ Loss G: 1.5647 \\ \n",
      "Epoch : [763/1000] \\ Loss D: 0.4175  \\ Loss G: 2.3803 \\ \n",
      "Epoch : [764/1000] \\ Loss D: 0.4647  \\ Loss G: 1.4151 \\ \n",
      "Epoch : [765/1000] \\ Loss D: 0.5299  \\ Loss G: 1.1560 \\ \n",
      "Epoch : [766/1000] \\ Loss D: 0.4742  \\ Loss G: 1.4419 \\ \n",
      "Epoch : [767/1000] \\ Loss D: 0.4167  \\ Loss G: 1.6418 \\ \n",
      "Epoch : [768/1000] \\ Loss D: 0.4843  \\ Loss G: 1.1257 \\ \n",
      "Epoch : [769/1000] \\ Loss D: 0.5253  \\ Loss G: 1.3905 \\ \n",
      "Epoch : [770/1000] \\ Loss D: 0.4558  \\ Loss G: 2.1010 \\ \n",
      "Epoch : [771/1000] \\ Loss D: 0.4001  \\ Loss G: 1.9487 \\ \n",
      "Epoch : [772/1000] \\ Loss D: 0.4214  \\ Loss G: 1.2600 \\ \n",
      "Epoch : [773/1000] \\ Loss D: 0.5003  \\ Loss G: 1.3084 \\ \n",
      "Epoch : [774/1000] \\ Loss D: 0.5639  \\ Loss G: 1.2281 \\ \n",
      "Epoch : [775/1000] \\ Loss D: 0.6536  \\ Loss G: 1.7176 \\ \n",
      "Epoch : [776/1000] \\ Loss D: 0.4932  \\ Loss G: 1.4023 \\ \n",
      "Epoch : [777/1000] \\ Loss D: 0.3652  \\ Loss G: 1.7470 \\ \n",
      "Epoch : [778/1000] \\ Loss D: 0.4686  \\ Loss G: 1.5218 \\ \n",
      "Epoch : [779/1000] \\ Loss D: 0.5315  \\ Loss G: 1.5456 \\ \n",
      "Epoch : [780/1000] \\ Loss D: 0.5773  \\ Loss G: 1.2438 \\ \n",
      "Epoch : [781/1000] \\ Loss D: 0.3765  \\ Loss G: 1.8848 \\ \n",
      "Epoch : [782/1000] \\ Loss D: 0.6406  \\ Loss G: 1.9190 \\ \n",
      "Epoch : [783/1000] \\ Loss D: 0.3760  \\ Loss G: 1.6676 \\ \n",
      "Epoch : [784/1000] \\ Loss D: 0.5054  \\ Loss G: 1.2869 \\ \n",
      "Epoch : [785/1000] \\ Loss D: 0.5728  \\ Loss G: 1.1384 \\ \n",
      "Epoch : [786/1000] \\ Loss D: 0.6419  \\ Loss G: 1.1362 \\ \n",
      "Epoch : [787/1000] \\ Loss D: 0.5486  \\ Loss G: 1.8350 \\ \n",
      "Epoch : [788/1000] \\ Loss D: 0.3756  \\ Loss G: 1.4551 \\ \n",
      "Epoch : [789/1000] \\ Loss D: 0.3935  \\ Loss G: 1.6688 \\ \n",
      "Epoch : [790/1000] \\ Loss D: 0.3497  \\ Loss G: 1.8904 \\ \n",
      "Epoch : [791/1000] \\ Loss D: 0.3985  \\ Loss G: 1.7248 \\ \n",
      "Epoch : [792/1000] \\ Loss D: 0.4994  \\ Loss G: 1.6172 \\ \n",
      "Epoch : [793/1000] \\ Loss D: 0.5405  \\ Loss G: 1.8198 \\ \n",
      "Epoch : [794/1000] \\ Loss D: 0.6526  \\ Loss G: 1.3541 \\ \n",
      "Epoch : [795/1000] \\ Loss D: 0.5194  \\ Loss G: 1.6216 \\ \n",
      "Epoch : [796/1000] \\ Loss D: 0.5020  \\ Loss G: 1.2562 \\ \n",
      "Epoch : [797/1000] \\ Loss D: 0.5186  \\ Loss G: 1.4535 \\ \n",
      "Epoch : [798/1000] \\ Loss D: 0.4918  \\ Loss G: 1.4808 \\ \n",
      "Epoch : [799/1000] \\ Loss D: 0.5129  \\ Loss G: 1.6268 \\ \n",
      "Epoch : [800/1000] \\ Loss D: 0.5793  \\ Loss G: 1.5919 \\ \n",
      "Epoch : [801/1000] \\ Loss D: 0.4294  \\ Loss G: 1.5659 \\ \n",
      "Epoch : [802/1000] \\ Loss D: 0.4468  \\ Loss G: 1.5163 \\ \n",
      "Epoch : [803/1000] \\ Loss D: 0.4738  \\ Loss G: 1.5741 \\ \n",
      "Epoch : [804/1000] \\ Loss D: 0.5168  \\ Loss G: 1.7373 \\ \n",
      "Epoch : [805/1000] \\ Loss D: 0.4713  \\ Loss G: 1.7012 \\ \n",
      "Epoch : [806/1000] \\ Loss D: 0.4905  \\ Loss G: 1.7779 \\ \n",
      "Epoch : [807/1000] \\ Loss D: 0.5392  \\ Loss G: 1.7324 \\ \n",
      "Epoch : [808/1000] \\ Loss D: 0.3443  \\ Loss G: 1.7861 \\ \n",
      "Epoch : [809/1000] \\ Loss D: 0.4931  \\ Loss G: 1.5734 \\ \n",
      "Epoch : [810/1000] \\ Loss D: 0.5935  \\ Loss G: 1.3720 \\ \n",
      "Epoch : [811/1000] \\ Loss D: 0.3932  \\ Loss G: 1.6173 \\ \n",
      "Epoch : [812/1000] \\ Loss D: 0.4531  \\ Loss G: 1.5842 \\ \n",
      "Epoch : [813/1000] \\ Loss D: 0.6263  \\ Loss G: 1.4282 \\ \n",
      "Epoch : [814/1000] \\ Loss D: 0.4366  \\ Loss G: 1.3403 \\ \n",
      "Epoch : [815/1000] \\ Loss D: 0.3803  \\ Loss G: 1.8259 \\ \n",
      "Epoch : [816/1000] \\ Loss D: 0.5043  \\ Loss G: 1.2967 \\ \n",
      "Epoch : [817/1000] \\ Loss D: 0.5954  \\ Loss G: 1.1450 \\ \n",
      "Epoch : [818/1000] \\ Loss D: 0.5412  \\ Loss G: 1.2643 \\ \n",
      "Epoch : [819/1000] \\ Loss D: 0.5384  \\ Loss G: 1.4206 \\ \n",
      "Epoch : [820/1000] \\ Loss D: 0.5469  \\ Loss G: 1.4141 \\ \n",
      "Epoch : [821/1000] \\ Loss D: 0.4646  \\ Loss G: 1.6411 \\ \n",
      "Epoch : [822/1000] \\ Loss D: 0.5276  \\ Loss G: 1.3374 \\ \n",
      "Epoch : [823/1000] \\ Loss D: 0.4614  \\ Loss G: 1.6525 \\ \n",
      "Epoch : [824/1000] \\ Loss D: 0.4061  \\ Loss G: 1.4634 \\ \n",
      "Epoch : [825/1000] \\ Loss D: 0.3905  \\ Loss G: 1.5154 \\ \n",
      "Epoch : [826/1000] \\ Loss D: 0.4754  \\ Loss G: 1.5739 \\ \n",
      "Epoch : [827/1000] \\ Loss D: 0.4467  \\ Loss G: 1.8473 \\ \n",
      "Epoch : [828/1000] \\ Loss D: 0.5622  \\ Loss G: 2.0976 \\ \n",
      "Epoch : [829/1000] \\ Loss D: 0.4533  \\ Loss G: 1.6936 \\ \n",
      "Epoch : [830/1000] \\ Loss D: 0.5511  \\ Loss G: 1.4980 \\ \n",
      "Epoch : [831/1000] \\ Loss D: 0.4886  \\ Loss G: 1.5171 \\ \n",
      "Epoch : [832/1000] \\ Loss D: 0.4477  \\ Loss G: 1.8448 \\ \n",
      "Epoch : [833/1000] \\ Loss D: 0.5548  \\ Loss G: 2.2960 \\ \n",
      "Epoch : [834/1000] \\ Loss D: 0.3613  \\ Loss G: 1.8295 \\ \n",
      "Epoch : [835/1000] \\ Loss D: 0.4679  \\ Loss G: 1.9214 \\ \n",
      "Epoch : [836/1000] \\ Loss D: 0.4257  \\ Loss G: 1.1947 \\ \n",
      "Epoch : [837/1000] \\ Loss D: 0.6182  \\ Loss G: 0.9206 \\ \n",
      "Epoch : [838/1000] \\ Loss D: 0.5059  \\ Loss G: 2.0028 \\ \n",
      "Epoch : [839/1000] \\ Loss D: 0.4571  \\ Loss G: 1.4959 \\ \n",
      "Epoch : [840/1000] \\ Loss D: 0.4462  \\ Loss G: 1.5843 \\ \n",
      "Epoch : [841/1000] \\ Loss D: 0.4794  \\ Loss G: 1.9517 \\ \n",
      "Epoch : [842/1000] \\ Loss D: 0.5034  \\ Loss G: 1.3437 \\ \n",
      "Epoch : [843/1000] \\ Loss D: 0.4529  \\ Loss G: 1.5055 \\ \n",
      "Epoch : [844/1000] \\ Loss D: 0.4240  \\ Loss G: 1.3758 \\ \n",
      "Epoch : [845/1000] \\ Loss D: 0.4853  \\ Loss G: 1.6220 \\ \n",
      "Epoch : [846/1000] \\ Loss D: 0.6095  \\ Loss G: 1.2622 \\ \n",
      "Epoch : [847/1000] \\ Loss D: 0.5525  \\ Loss G: 1.5021 \\ \n",
      "Epoch : [848/1000] \\ Loss D: 0.4350  \\ Loss G: 1.5906 \\ \n",
      "Epoch : [849/1000] \\ Loss D: 0.5143  \\ Loss G: 1.4028 \\ \n",
      "Epoch : [850/1000] \\ Loss D: 0.4999  \\ Loss G: 1.8042 \\ \n",
      "Epoch : [851/1000] \\ Loss D: 0.5676  \\ Loss G: 1.6331 \\ \n",
      "Epoch : [852/1000] \\ Loss D: 0.4785  \\ Loss G: 1.5480 \\ \n",
      "Epoch : [853/1000] \\ Loss D: 0.4181  \\ Loss G: 1.7231 \\ \n",
      "Epoch : [854/1000] \\ Loss D: 0.3754  \\ Loss G: 1.7236 \\ \n",
      "Epoch : [855/1000] \\ Loss D: 0.4773  \\ Loss G: 1.9515 \\ \n",
      "Epoch : [856/1000] \\ Loss D: 0.4658  \\ Loss G: 1.5366 \\ \n",
      "Epoch : [857/1000] \\ Loss D: 0.4237  \\ Loss G: 1.5633 \\ \n",
      "Epoch : [858/1000] \\ Loss D: 0.3957  \\ Loss G: 1.5991 \\ \n",
      "Epoch : [859/1000] \\ Loss D: 0.3255  \\ Loss G: 1.7606 \\ \n",
      "Epoch : [860/1000] \\ Loss D: 0.4925  \\ Loss G: 1.6169 \\ \n",
      "Epoch : [861/1000] \\ Loss D: 0.5080  \\ Loss G: 1.7572 \\ \n",
      "Epoch : [862/1000] \\ Loss D: 0.3814  \\ Loss G: 1.7740 \\ \n",
      "Epoch : [863/1000] \\ Loss D: 0.3872  \\ Loss G: 2.0834 \\ \n",
      "Epoch : [864/1000] \\ Loss D: 0.3411  \\ Loss G: 1.8030 \\ \n",
      "Epoch : [865/1000] \\ Loss D: 0.3816  \\ Loss G: 1.7335 \\ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [866/1000] \\ Loss D: 0.5344  \\ Loss G: 1.4659 \\ \n",
      "Epoch : [867/1000] \\ Loss D: 0.4721  \\ Loss G: 1.4842 \\ \n",
      "Epoch : [868/1000] \\ Loss D: 0.5269  \\ Loss G: 1.6508 \\ \n",
      "Epoch : [869/1000] \\ Loss D: 0.4021  \\ Loss G: 1.7884 \\ \n",
      "Epoch : [870/1000] \\ Loss D: 0.4513  \\ Loss G: 1.7355 \\ \n",
      "Epoch : [871/1000] \\ Loss D: 0.4869  \\ Loss G: 1.8118 \\ \n",
      "Epoch : [872/1000] \\ Loss D: 0.6171  \\ Loss G: 1.4142 \\ \n",
      "Epoch : [873/1000] \\ Loss D: 0.4193  \\ Loss G: 1.6499 \\ \n",
      "Epoch : [874/1000] \\ Loss D: 0.4754  \\ Loss G: 1.4738 \\ \n",
      "Epoch : [875/1000] \\ Loss D: 0.5120  \\ Loss G: 1.4595 \\ \n",
      "Epoch : [876/1000] \\ Loss D: 0.4067  \\ Loss G: 1.5353 \\ \n",
      "Epoch : [877/1000] \\ Loss D: 0.5649  \\ Loss G: 1.0779 \\ \n",
      "Epoch : [878/1000] \\ Loss D: 0.4948  \\ Loss G: 1.5054 \\ \n",
      "Epoch : [879/1000] \\ Loss D: 0.4972  \\ Loss G: 2.0560 \\ \n",
      "Epoch : [880/1000] \\ Loss D: 0.4532  \\ Loss G: 1.6663 \\ \n",
      "Epoch : [881/1000] \\ Loss D: 0.5109  \\ Loss G: 1.7307 \\ \n",
      "Epoch : [882/1000] \\ Loss D: 0.3826  \\ Loss G: 1.5445 \\ \n",
      "Epoch : [883/1000] \\ Loss D: 0.5661  \\ Loss G: 1.3082 \\ \n",
      "Epoch : [884/1000] \\ Loss D: 0.4337  \\ Loss G: 1.2346 \\ \n",
      "Epoch : [885/1000] \\ Loss D: 0.3835  \\ Loss G: 1.8272 \\ \n",
      "Epoch : [886/1000] \\ Loss D: 0.6399  \\ Loss G: 1.5254 \\ \n",
      "Epoch : [887/1000] \\ Loss D: 0.3585  \\ Loss G: 1.8777 \\ \n",
      "Epoch : [888/1000] \\ Loss D: 0.4362  \\ Loss G: 2.2047 \\ \n",
      "Epoch : [889/1000] \\ Loss D: 0.4637  \\ Loss G: 1.3090 \\ \n",
      "Epoch : [890/1000] \\ Loss D: 0.5078  \\ Loss G: 1.7380 \\ \n",
      "Epoch : [891/1000] \\ Loss D: 0.5200  \\ Loss G: 1.7573 \\ \n",
      "Epoch : [892/1000] \\ Loss D: 0.4227  \\ Loss G: 2.0108 \\ \n",
      "Epoch : [893/1000] \\ Loss D: 0.5172  \\ Loss G: 1.5263 \\ \n",
      "Epoch : [894/1000] \\ Loss D: 0.4646  \\ Loss G: 2.5163 \\ \n",
      "Epoch : [895/1000] \\ Loss D: 0.4866  \\ Loss G: 1.6046 \\ \n",
      "Epoch : [896/1000] \\ Loss D: 0.5625  \\ Loss G: 1.2702 \\ \n",
      "Epoch : [897/1000] \\ Loss D: 0.4227  \\ Loss G: 1.6806 \\ \n",
      "Epoch : [898/1000] \\ Loss D: 0.5336  \\ Loss G: 1.3103 \\ \n",
      "Epoch : [899/1000] \\ Loss D: 0.4942  \\ Loss G: 1.5744 \\ \n",
      "Epoch : [900/1000] \\ Loss D: 0.5069  \\ Loss G: 1.8385 \\ \n",
      "Epoch : [901/1000] \\ Loss D: 0.4928  \\ Loss G: 1.4439 \\ \n",
      "Epoch : [902/1000] \\ Loss D: 0.4823  \\ Loss G: 1.4682 \\ \n",
      "Epoch : [903/1000] \\ Loss D: 0.5254  \\ Loss G: 1.4466 \\ \n",
      "Epoch : [904/1000] \\ Loss D: 0.5243  \\ Loss G: 1.9228 \\ \n",
      "Epoch : [905/1000] \\ Loss D: 0.5590  \\ Loss G: 1.8585 \\ \n",
      "Epoch : [906/1000] \\ Loss D: 0.4862  \\ Loss G: 1.8761 \\ \n",
      "Epoch : [907/1000] \\ Loss D: 0.2976  \\ Loss G: 1.8054 \\ \n",
      "Epoch : [908/1000] \\ Loss D: 0.4854  \\ Loss G: 1.7400 \\ \n",
      "Epoch : [909/1000] \\ Loss D: 0.4360  \\ Loss G: 1.8237 \\ \n",
      "Epoch : [910/1000] \\ Loss D: 0.4494  \\ Loss G: 1.7491 \\ \n",
      "Epoch : [911/1000] \\ Loss D: 0.3752  \\ Loss G: 1.6221 \\ \n",
      "Epoch : [912/1000] \\ Loss D: 0.5047  \\ Loss G: 1.5345 \\ \n",
      "Epoch : [913/1000] \\ Loss D: 0.5334  \\ Loss G: 1.0188 \\ \n",
      "Epoch : [914/1000] \\ Loss D: 0.4689  \\ Loss G: 1.6205 \\ \n",
      "Epoch : [915/1000] \\ Loss D: 0.5299  \\ Loss G: 1.4669 \\ \n",
      "Epoch : [916/1000] \\ Loss D: 0.4238  \\ Loss G: 1.8528 \\ \n",
      "Epoch : [917/1000] \\ Loss D: 0.4557  \\ Loss G: 1.7020 \\ \n",
      "Epoch : [918/1000] \\ Loss D: 0.5446  \\ Loss G: 1.5392 \\ \n",
      "Epoch : [919/1000] \\ Loss D: 0.5532  \\ Loss G: 1.2162 \\ \n",
      "Epoch : [920/1000] \\ Loss D: 0.5057  \\ Loss G: 1.2644 \\ \n",
      "Epoch : [921/1000] \\ Loss D: 0.4959  \\ Loss G: 1.4842 \\ \n",
      "Epoch : [922/1000] \\ Loss D: 0.4100  \\ Loss G: 1.6802 \\ \n",
      "Epoch : [923/1000] \\ Loss D: 0.3849  \\ Loss G: 2.1032 \\ \n",
      "Epoch : [924/1000] \\ Loss D: 0.3523  \\ Loss G: 1.5652 \\ \n",
      "Epoch : [925/1000] \\ Loss D: 0.5082  \\ Loss G: 1.3039 \\ \n",
      "Epoch : [926/1000] \\ Loss D: 0.4200  \\ Loss G: 1.1255 \\ \n",
      "Epoch : [927/1000] \\ Loss D: 0.4103  \\ Loss G: 1.6803 \\ \n",
      "Epoch : [928/1000] \\ Loss D: 0.4663  \\ Loss G: 1.7155 \\ \n",
      "Epoch : [929/1000] \\ Loss D: 0.3907  \\ Loss G: 1.5467 \\ \n",
      "Epoch : [930/1000] \\ Loss D: 0.3629  \\ Loss G: 2.1046 \\ \n",
      "Epoch : [931/1000] \\ Loss D: 0.3697  \\ Loss G: 1.9888 \\ \n",
      "Epoch : [932/1000] \\ Loss D: 0.4835  \\ Loss G: 1.8128 \\ \n",
      "Epoch : [933/1000] \\ Loss D: 0.3411  \\ Loss G: 2.1086 \\ \n",
      "Epoch : [934/1000] \\ Loss D: 0.4696  \\ Loss G: 1.8742 \\ \n",
      "Epoch : [935/1000] \\ Loss D: 0.4910  \\ Loss G: 1.3068 \\ \n",
      "Epoch : [936/1000] \\ Loss D: 0.5829  \\ Loss G: 1.3607 \\ \n",
      "Epoch : [937/1000] \\ Loss D: 0.4620  \\ Loss G: 1.8958 \\ \n",
      "Epoch : [938/1000] \\ Loss D: 0.4694  \\ Loss G: 1.8037 \\ \n",
      "Epoch : [939/1000] \\ Loss D: 0.3647  \\ Loss G: 1.5533 \\ \n",
      "Epoch : [940/1000] \\ Loss D: 0.5076  \\ Loss G: 1.7117 \\ \n",
      "Epoch : [941/1000] \\ Loss D: 0.4584  \\ Loss G: 1.4742 \\ \n",
      "Epoch : [942/1000] \\ Loss D: 0.4010  \\ Loss G: 1.7248 \\ \n",
      "Epoch : [943/1000] \\ Loss D: 0.5450  \\ Loss G: 1.3398 \\ \n",
      "Epoch : [944/1000] \\ Loss D: 0.3529  \\ Loss G: 1.5360 \\ \n",
      "Epoch : [945/1000] \\ Loss D: 0.4582  \\ Loss G: 1.2241 \\ \n",
      "Epoch : [946/1000] \\ Loss D: 0.6060  \\ Loss G: 1.1534 \\ \n",
      "Epoch : [947/1000] \\ Loss D: 0.4793  \\ Loss G: 1.4661 \\ \n",
      "Epoch : [948/1000] \\ Loss D: 0.4329  \\ Loss G: 1.6519 \\ \n",
      "Epoch : [949/1000] \\ Loss D: 0.4356  \\ Loss G: 1.6975 \\ \n",
      "Epoch : [950/1000] \\ Loss D: 0.4958  \\ Loss G: 1.4693 \\ \n",
      "Epoch : [951/1000] \\ Loss D: 0.3081  \\ Loss G: 2.0340 \\ \n",
      "Epoch : [952/1000] \\ Loss D: 0.5450  \\ Loss G: 1.7451 \\ \n",
      "Epoch : [953/1000] \\ Loss D: 0.4921  \\ Loss G: 1.4554 \\ \n",
      "Epoch : [954/1000] \\ Loss D: 0.5394  \\ Loss G: 1.3721 \\ \n",
      "Epoch : [955/1000] \\ Loss D: 0.5346  \\ Loss G: 1.2157 \\ \n",
      "Epoch : [956/1000] \\ Loss D: 0.3740  \\ Loss G: 1.7178 \\ \n",
      "Epoch : [957/1000] \\ Loss D: 0.4667  \\ Loss G: 1.4681 \\ \n",
      "Epoch : [958/1000] \\ Loss D: 0.3985  \\ Loss G: 1.8450 \\ \n",
      "Epoch : [959/1000] \\ Loss D: 0.5492  \\ Loss G: 1.5642 \\ \n",
      "Epoch : [960/1000] \\ Loss D: 0.4697  \\ Loss G: 1.9359 \\ \n",
      "Epoch : [961/1000] \\ Loss D: 0.4823  \\ Loss G: 1.1516 \\ \n",
      "Epoch : [962/1000] \\ Loss D: 0.4368  \\ Loss G: 1.7421 \\ \n",
      "Epoch : [963/1000] \\ Loss D: 0.3039  \\ Loss G: 1.8682 \\ \n",
      "Epoch : [964/1000] \\ Loss D: 0.4204  \\ Loss G: 1.6146 \\ \n",
      "Epoch : [965/1000] \\ Loss D: 0.5007  \\ Loss G: 1.2539 \\ \n",
      "Epoch : [966/1000] \\ Loss D: 0.3044  \\ Loss G: 2.2043 \\ \n",
      "Epoch : [967/1000] \\ Loss D: 0.3711  \\ Loss G: 1.7244 \\ \n",
      "Epoch : [968/1000] \\ Loss D: 0.3536  \\ Loss G: 1.6123 \\ \n",
      "Epoch : [969/1000] \\ Loss D: 0.5564  \\ Loss G: 1.5004 \\ \n",
      "Epoch : [970/1000] \\ Loss D: 0.4527  \\ Loss G: 1.7456 \\ \n",
      "Epoch : [971/1000] \\ Loss D: 0.4426  \\ Loss G: 1.7584 \\ \n",
      "Epoch : [972/1000] \\ Loss D: 0.5830  \\ Loss G: 1.5409 \\ \n",
      "Epoch : [973/1000] \\ Loss D: 0.5453  \\ Loss G: 1.4073 \\ \n",
      "Epoch : [974/1000] \\ Loss D: 0.4743  \\ Loss G: 1.6630 \\ \n",
      "Epoch : [975/1000] \\ Loss D: 0.4970  \\ Loss G: 1.5101 \\ \n",
      "Epoch : [976/1000] \\ Loss D: 0.5294  \\ Loss G: 1.4559 \\ \n",
      "Epoch : [977/1000] \\ Loss D: 0.4292  \\ Loss G: 1.7596 \\ \n",
      "Epoch : [978/1000] \\ Loss D: 0.5151  \\ Loss G: 1.8395 \\ \n",
      "Epoch : [979/1000] \\ Loss D: 0.4030  \\ Loss G: 1.7852 \\ \n",
      "Epoch : [980/1000] \\ Loss D: 0.4364  \\ Loss G: 1.4056 \\ \n",
      "Epoch : [981/1000] \\ Loss D: 0.5200  \\ Loss G: 1.6646 \\ \n",
      "Epoch : [982/1000] \\ Loss D: 0.5437  \\ Loss G: 1.2474 \\ \n",
      "Epoch : [983/1000] \\ Loss D: 0.4757  \\ Loss G: 1.8734 \\ \n",
      "Epoch : [984/1000] \\ Loss D: 0.3268  \\ Loss G: 2.1832 \\ \n",
      "Epoch : [985/1000] \\ Loss D: 0.4987  \\ Loss G: 1.5275 \\ \n",
      "Epoch : [986/1000] \\ Loss D: 0.4029  \\ Loss G: 2.3111 \\ \n",
      "Epoch : [987/1000] \\ Loss D: 0.4987  \\ Loss G: 2.0585 \\ \n",
      "Epoch : [988/1000] \\ Loss D: 0.5958  \\ Loss G: 1.1461 \\ \n",
      "Epoch : [989/1000] \\ Loss D: 0.5673  \\ Loss G: 1.4680 \\ \n",
      "Epoch : [990/1000] \\ Loss D: 0.4959  \\ Loss G: 1.6994 \\ \n",
      "Epoch : [991/1000] \\ Loss D: 0.5114  \\ Loss G: 1.5258 \\ \n",
      "Epoch : [992/1000] \\ Loss D: 0.4942  \\ Loss G: 1.8327 \\ \n",
      "Epoch : [993/1000] \\ Loss D: 0.4126  \\ Loss G: 1.5592 \\ \n",
      "Epoch : [994/1000] \\ Loss D: 0.5581  \\ Loss G: 1.2907 \\ \n",
      "Epoch : [995/1000] \\ Loss D: 0.4852  \\ Loss G: 1.7915 \\ \n",
      "Epoch : [996/1000] \\ Loss D: 0.5238  \\ Loss G: 1.3271 \\ \n",
      "Epoch : [997/1000] \\ Loss D: 0.3359  \\ Loss G: 2.1154 \\ \n",
      "Epoch : [998/1000] \\ Loss D: 0.3461  \\ Loss G: 2.2669 \\ \n",
      "Epoch : [999/1000] \\ Loss D: 0.4616  \\ Loss G: 1.6999 \\ \n",
      "Epoch : [1000/1000] \\ Loss D: 0.5179  \\ Loss G: 1.2884 \\ \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs+1):\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        real=real.view(-1,784).to(device)\n",
    "        batch_size=real.shape[0]\n",
    "\n",
    "        #Training Discriminator\n",
    "        noise=torch.randn((batch_size,n_dim)).to(device)\n",
    "        fake=genr(noise)\n",
    "        discr_real=discr(real).view(-1)\n",
    "        loss_discr_real=loss(discr_real,torch.ones_like(discr_real))\n",
    "        discr_fake=discr(fake).view(-1)\n",
    "        loss_discr_fake=loss(discr_fake,torch.zeros_like(discr_fake))\n",
    "        loss_discr=(loss_discr_fake+loss_discr_real)/2 #Average Loss\n",
    "        discr.zero_grad()\n",
    "        loss_discr.backward(retain_graph=True)\n",
    "        opt_discr.step()\n",
    "        \n",
    "        #Training Generator\n",
    "        \n",
    "        output=discr(fake).view(-1)\n",
    "        loss_genr=loss(output,torch.ones_like(output))\n",
    "        genr.zero_grad()\n",
    "        loss_genr.backward()\n",
    "        opt_genr.step()\n",
    "        \n",
    "\n",
    "        \n",
    "        if batch_idx ==0:\n",
    "            print(\n",
    "                f\"Epoch : [{epoch}/{epochs}] \\ \"\n",
    "                f\"Loss D: {loss_discr:.4f}  \\ \"\n",
    "                f\"Loss G: {loss_genr:.4f} \\ \"\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                fake=genr(fixed_noise).reshape(-1,1,28,28)\n",
    "                data=real.reshape(-1,1,28,28)\n",
    "                img_grid_fake=torchvision.utils.make_grid(fake,normalize=True)\n",
    "                img_grid_real=torchvision.utils.make_grid(data,normalize=True)\n",
    "                \n",
    "                writer_fake.add_image(\n",
    "                    \"MNIST FakeImages\", img_grid_fake, global_step=step\n",
    "                )\n",
    "                writer_real.add_image(\n",
    "                    \"MNIST FakeImages\", img_grid_real, global_step=step\n",
    "                )\n",
    "                step+=1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86a2d7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c2e9ba515e52555\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c2e9ba515e52555\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4804450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
